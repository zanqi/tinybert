{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zanqi/tinybert/blob/main/bert_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kC7VRPdCFlLf"
      },
      "source": [
        "### Getting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc5qXnJ8tf6a",
        "outputId": "37169772-fbea-454a-a057-e62b7d0ff251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-07-13 01:45:48--  https://raw.githubusercontent.com/zanqi/tinybert/main/news.tsv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10694395 (10M) [application/zip]\n",
            "Saving to: ‘news.tsv.zip’\n",
            "\n",
            "news.tsv.zip        100%[===================>]  10.20M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-07-13 01:45:48 (115 MB/s) - ‘news.tsv.zip’ saved [10694395/10694395]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the MIND dataset\n",
        "!wget https://raw.githubusercontent.com/zanqi/tinybert/main/news.tsv.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O shakespeare.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIL6IVSTgHyy",
        "outputId": "e525ce5b-23dd-4b00-850f-6fe023dd27e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  news.tsv.zip\n",
            "  inflating: news.tsv                \n"
          ]
        }
      ],
      "source": [
        "! unzip {'news.tsv.zip'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYEVguyIxRkU",
        "outputId": "760cfd43-74e2-479a-a498-ebf4400483a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (4.30.2)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (1.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: click in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from nltk) (1.3.1)\n",
            "Requirement already satisfied: fsspec in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2023.5.7)\n",
            "Installing collected packages: nltk\n",
            "Successfully installed nltk-3.8.1\n"
          ]
        }
      ],
      "source": [
        "! pip3 install transformers nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUba-f4ytoUZ",
        "outputId": "ca1bd3a6-f345-4d94-89b7-7e303ca46240"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/zanqiliang/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import ssl\n",
        "try:\n",
        "\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "    \n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZYqD6ivcuOHj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "with open('shakespeare.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "sents = nltk.sent_tokenize(text) # list(str)\n",
        "\n",
        "n = len(sents)\n",
        "train_data = sents[:int(n*0.9)]\n",
        "val_data = sents[int(n*0.9):]\n",
        "\n",
        "#shakespeare\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data), (batch_size,))\n",
        "    sents1 = [data[i] for i in ix]\n",
        "    x = tokenizer(sents1, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    token_ids = torch.LongTensor(x[\"input_ids\"])\n",
        "    attention_mask = torch.LongTensor(x[\"attention_mask\"])\n",
        "    special = torch.isin(token_ids, torch.tensor(tokenizer.all_special_ids))\n",
        "    mask = torch.rand(token_ids.shape) < 0.15\n",
        "    \n",
        "    mask = mask & (attention_mask == 1) & ~special\n",
        "    mask_mask = (torch.rand(token_ids.shape) < 0.8) & mask\n",
        "    mask_rand = (torch.rand(token_ids.shape) < 0.5) & mask & ~mask_mask\n",
        "\n",
        "    y = token_ids.detach().clone()\n",
        "    y[~mask] = -100\n",
        "    counts.update(y[y != -100].tolist())\n",
        "\n",
        "    token_ids[mask_mask] = tokenizer.mask_token_id\n",
        "    token_ids[mask_rand] = torch.randint(\n",
        "        tokenizer.vocab_size, token_ids[mask_rand].shape\n",
        "    )\n",
        "\n",
        "    return x.to(device), y.to(device), None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "\n",
        "batch_size = 16\n",
        "device = 'cpu'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "counts = Counter()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('news.tsv',header=None,sep='\\t')\n",
        "\n",
        "data.columns=['News ID',\n",
        "\"Category\",\n",
        "\"SubCategory\",\n",
        "\"Title\",\n",
        "\"Abstract\",\n",
        "\"URL\",\n",
        "\"Title Entities\",\n",
        "\"Abstract Entities \"]\n",
        "\n",
        "text_data = data.iloc[:, 3:5]\n",
        "text_data.Abstract.str.len().describe()\n",
        "\n",
        "# abstracts = text_data.Abstract\n",
        "sents_by_abstract = [nltk.sent_tokenize(a) for a in text_data[text_data.Abstract.str.len() > 10].Abstract]\n",
        "abstracts = [sents for sents in sents_by_abstract if len(sents) > 1]\n",
        "# len(abstracts), abstracts[:10]\n",
        "\n",
        "zipped = [zip(a, a[1:]) for a in abstracts]\n",
        "pairs = [(s1, s2) for z in zipped for s1, s2 in z]\n",
        "\n",
        "n = int(0.9*len(pairs)) # first 90% will be train, rest val\n",
        "train_data = pairs[:n]\n",
        "val_data = pairs[n:]\n",
        "\n",
        "# news\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data), (batch_size,))\n",
        "    ix_mask = torch.rand(batch_size) < 0.5\n",
        "    next_ix = ix.detach().clone()\n",
        "    next_ix[ix_mask] = (ix[ix_mask] + 10) % len(data)\n",
        "    sents1 = [\"\".join(data[i]) for i in ix]\n",
        "    # sents1 = [\"\".join(data[i][: len(data[i]) // 2]) for i in ix]\n",
        "    # sents2 = [\"\".join(data[i][len(data[i]) // 2 :]) for i in next_ix]\n",
        "    # x = tokenizer(sents1, sents2, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    x = tokenizer(sents1, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    token_ids = torch.LongTensor(x[\"input_ids\"])\n",
        "    attention_mask = torch.LongTensor(x[\"attention_mask\"])\n",
        "    special = torch.isin(token_ids, torch.tensor(tokenizer.all_special_ids))\n",
        "    mask = torch.rand(token_ids.shape) < 0.15\n",
        "    most_common = torch.isin(\n",
        "        token_ids, torch.tensor(counts.most_common(len(counts) // 20))\n",
        "    )\n",
        "    mask = mask & (attention_mask == 1) & ~special & ~most_common\n",
        "    # mask = mask & (attention_mask == 1) & ~special\n",
        "    mask_mask = (torch.rand(token_ids.shape) < 0.8) & mask\n",
        "    mask_rand = (torch.rand(token_ids.shape) < 0.5) & mask & ~mask_mask\n",
        "\n",
        "    y = token_ids.detach().clone()\n",
        "    y[~mask] = -100\n",
        "    counts.update(y[y != -100].tolist())\n",
        "\n",
        "    token_ids[mask_mask] = tokenizer.mask_token_id\n",
        "    token_ids[mask_rand] = torch.randint(\n",
        "        tokenizer.vocab_size, token_ids[mask_rand].shape\n",
        "    )\n",
        "\n",
        "    nsp_target = ix == next_ix\n",
        "    return x.to(device), y.to(device), nsp_target.long().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "VjUv3VFCrm5R",
        "outputId": "8ec8a10d-8809-4569-a8ae-50be4713417d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Real talk. Demi Moore got candid about a variety of topics in her new book, Inside Out, including her famous exes, substance abuse struggles and her heartbreaking sexual assault. \"The same question kept going through my head: How did I get here?\" the 56-year-old actress began in the memoir, which was released on Tuesday, September 24. \"The husband who I\\'d thought was the love of my life had cheated on me and then decided he didn\\'t want to work on our marriage. My children weren\\'t speaking me. … Is this life? I wondered. Because if this is it, I\\'m done.\" Moore provided insight into all three of her marriages in the book. She was married to Freddy Moore from 1980 to 1985, Bruce Willis from 1987 to 2000 and Ashton Kutcher from 2005 to 2013. The end of the G.I. Jane star\\'s relationship with the former That 70\\'s Show star, however, seemed to have the biggest impact on her. \"I lost me,\" the Ghost actress told Diane Sawyer on Good Morning America on Monday, September 23, about their split. \"I think the thing if I were to look back, I would say I blinded myself and I lost myself.\" Moore and Kutcher, who is 15 years her junior, started dating in 2003. After Us Weekly broke the news that he was allegedly unfaithful in 2011, the twosome called it quits. The Ranch star married Mila Kunis in July 2015. They share two kids: Wyatt, 4, and Dimitri, 2. Kutcher, for his part, reflected on the divorce during an appearance on Dax Shepard\\'s \"Armchair Expert\" podcast last year. \"Right after I got divorced, I went to the mountains for a week by myself,\" Kutcher told Shepard in February 2018. \"I did no food, no drink   just water and tea. I took all my computers away, my phone, my everything. I was there by myself, so there was no talking. I just had a notepad, a pen and water and tea   for a week.\" He referred to the trip as \"really spiritual and kind of awesome.\" \"I wrote down every single relationship that I had where I felt like there was some grudge or some anything, regret, anything,\" Kutcher explained. \"And I wrote letters to every single person, and on day seven, I typed them all out and then sent them.\" While Moore certainly doesn\\'t hold back in Inside Out, a source told Us earlier this month that the Kutcher isn\\'t worried about the book. \"Ashton knew what was coming. He had a heads up on what is in the book,\" the insider said on September 13. \"He\\'s not mad or disappointed. This is Demi\\'s truth, and he always felt sympathetic toward her. He knows her story and that her upbringing was difficult.\" Inside Out is available now. Scroll through for 10 revelations from the book:'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data.iloc[text_data.Abstract.str.len().argmax()].Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UO9X3jPaqd3F",
        "outputId": "eba2e7de-17ae-426e-e509-43c9d4ea2740"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
              "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50 Worst Habits For Belly Fat</td>\n",
              "      <td>These seemingly harmless habits are holding yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
              "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
              "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
              "      <td>They seem harmless, but there's a very good re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51275</th>\n",
              "      <td>Realme takes chunk of India mobile market as S...</td>\n",
              "      <td>Over 400 percent more phones shipped year-on-year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51276</th>\n",
              "      <td>Young Northeast Florida fans flock to U.S. wom...</td>\n",
              "      <td>When the U.S. women's national soccer team arr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51277</th>\n",
              "      <td>Adapting, Learning And Soul Searching: Reflect...</td>\n",
              "      <td>Woolsey Fire Anniversary: A community is forev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51279</th>\n",
              "      <td>St. Dominic soccer player tries to kick cancer...</td>\n",
              "      <td>Sometimes, what happens on the sidelines can b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51280</th>\n",
              "      <td>How the Sounders won MLS Cup</td>\n",
              "      <td>Mark, Jeremiah and Casey were so excited they ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48495 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Title  \\\n",
              "0      The Brands Queen Elizabeth, Prince Charles, an...   \n",
              "1                          50 Worst Habits For Belly Fat   \n",
              "2      The Cost of Trump's Aid Freeze in the Trenches...   \n",
              "3      I Was An NBA Wife. Here's How It Affected My M...   \n",
              "4      How to Get Rid of Skin Tags, According to a De...   \n",
              "...                                                  ...   \n",
              "51275  Realme takes chunk of India mobile market as S...   \n",
              "51276  Young Northeast Florida fans flock to U.S. wom...   \n",
              "51277  Adapting, Learning And Soul Searching: Reflect...   \n",
              "51279  St. Dominic soccer player tries to kick cancer...   \n",
              "51280                       How the Sounders won MLS Cup   \n",
              "\n",
              "                                                Abstract  \n",
              "0      Shop the notebooks, jackets, and more that the...  \n",
              "1      These seemingly harmless habits are holding yo...  \n",
              "2      Lt. Ivan Molchanets peeked over a parapet of s...  \n",
              "3      I felt like I was a fraud, and being an NBA wi...  \n",
              "4      They seem harmless, but there's a very good re...  \n",
              "...                                                  ...  \n",
              "51275  Over 400 percent more phones shipped year-on-year  \n",
              "51276  When the U.S. women's national soccer team arr...  \n",
              "51277  Woolsey Fire Anniversary: A community is forev...  \n",
              "51279  Sometimes, what happens on the sidelines can b...  \n",
              "51280  Mark, Jeremiah and Casey were so excited they ...  \n",
              "\n",
              "[48495 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data[text_data.Abstract.str.len() > 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCdxcMk6s2t8",
        "outputId": "7a2e9b43-75f8-45e0-875b-68a9856dee2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['My name is John E. Doe.', 'Please turn to p. 55.']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_text = nltk.sent_tokenize('My name is John E. Doe. Please turn to p. 55.')\n",
        "sent_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbnDJPixuQP-",
        "outputId": "3cbe92b5-19a2-4a48-8fc9-2031362faf72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in sentences:  74948\n",
            "length of dataset in words:  1427558\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset in sentences: \", sum(len(a) for a in abstracts))\n",
        "print(\"length of dataset in words: \", sum(len(nltk.word_tokenize(s)) for a in abstracts for s in a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "bra6rs5t0V5A",
        "outputId": "8d85ab53-1324-4f00-d398-9231b4628adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Lt. Ivan Molchanets peeked over a parapet of sand bags at the front line of the war in Ukraine.', 'Next to him was an empty helmet propped up to trick snipers, already perforated with multiple holes.')\n",
            "{'input_ids': [[101, 1045, 2371, 2066, 1045, 2001, 1037, 9861, 1010, 1998, 2108, 2019, 6452, 2564, 2134, 1005, 1056, 2393, 2008, 1012, 102], [101, 1999, 2755, 1010, 2009, 3053, 3908, 2033, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"[CLS] i felt like i was a fraud, and being an nba wife didn't help that. [SEP]\",\n",
              " '[CLS] in fact, it nearly destroyed me. [SEP]']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(train_data[0])\n",
        "encoded = tokenizer(train_data[1])\n",
        "print(encoded) # len(token_ids), tokenizer.decode(token_ids)\n",
        "tokenizer.batch_decode(encoded['input_ids'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([54, 23, 93, 26]), tensor([64, 33,  3, 36]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "# random.seed(1337)\n",
        "\n",
        "random.random()\n",
        "ix = torch.randint(100, (4,))\n",
        "mask = torch.rand(4) < 0.5\n",
        "next_ix = ix.detach().clone()\n",
        "next_ix[mask] = (ix[mask] + 10) % 100\n",
        "ix, next_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oKYVYCxpxP4b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "random.seed(1337)\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data), (batch_size,))\n",
        "  ix_mask = torch.rand(batch_size) < 0.5\n",
        "  next_ix = ix.detach().clone()\n",
        "  next_ix[ix_mask] = (ix[ix_mask] + 10) % len(data)\n",
        "  sents1 = [data[i][0] for i in ix]\n",
        "  sents2 = [data[i][1] for i in next_ix]\n",
        "  x = tokenizer(sents1, sents2, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "  token_ids = torch.LongTensor(x[\"input_ids\"])\n",
        "  attention_mask = torch.LongTensor(x[\"attention_mask\"])\n",
        "  cls = token_ids == tokenizer.cls_token_id\n",
        "  sep = token_ids == tokenizer.sep_token_id\n",
        "  special = cls | sep\n",
        "  mask = torch.rand(token_ids.shape) < 0.15\n",
        "  mask = mask & (attention_mask == 1) & ~special\n",
        "  mask_mask = (torch.rand(token_ids.shape) < 0.8) & mask\n",
        "  mask_rand = (torch.rand(token_ids.shape) < 0.5) & mask & ~mask_mask\n",
        "\n",
        "  y = token_ids.detach().clone()\n",
        "  y[~mask] = -100\n",
        "\n",
        "  token_ids[mask_mask] = tokenizer.mask_token_id\n",
        "  token_ids[mask_rand] = torch.randint(\n",
        "      0, tokenizer.vocab_size, token_ids[mask_rand].shape\n",
        "  )\n",
        "\n",
        "  nsp_target = ix == next_ix\n",
        "  return x, y, nsp_target.float().unsqueeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "emNNvihJCS2g",
        "outputId": "e4aa252e-0a31-41ef-a363-4634ba55c319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>input</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>moore</td>\n",
              "      <td>,</td>\n",
              "      <td>sc</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>fox</td>\n",
              "      <td>carolina</td>\n",
              "      <td>)</td>\n",
              "      <td>-</td>\n",
              "      <td>spartan</td>\n",
              "      <td>##burg</td>\n",
              "      <td>county</td>\n",
              "      <td>deputies</td>\n",
              "      <td>say</td>\n",
              "      <td>a</td>\n",
              "      <td>woman</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>recovering</td>\n",
              "      <td>after</td>\n",
              "      <td>being</td>\n",
              "      <td>shot</td>\n",
              "      <td>several</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>by</td>\n",
              "      <td>her</td>\n",
              "      <td>boyfriend</td>\n",
              "      <td>sunday</td>\n",
              "      <td>afternoon</td>\n",
              "      <td>.</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>construction</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>$</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>million</td>\n",
              "      <td>project</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>now</td>\n",
              "      <td>expected</td>\n",
              "      <td>to</td>\n",
              "      <td>begin</td>\n",
              "      <td>early</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>spring</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>about</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>months</td>\n",
              "      <td>connectivity</td>\n",
              "      <td>than</td>\n",
              "      <td>first</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>-</td>\n",
              "      <td>with</td>\n",
              "      <td>o</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>##up</td>\n",
              "      <td>##ancy</td>\n",
              "      <td>of</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>##s</td>\n",
              "      <td>by</td>\n",
              "      <td>the</td>\n",
              "      <td>end</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>[SEP]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>(</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>is</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>times</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>26</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>is</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>next</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>six</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>later</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>forecast</td>\n",
              "      <td>-</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>##cc</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>rental</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0      1      2      3       4      5         6      7      8   \\\n",
              "input   [CLS]  moore      ,     sc  [MASK]    fox  carolina      )      -   \n",
              "target  [UNK]  [UNK]  [UNK]  [UNK]       (  [UNK]     [UNK]  [UNK]  [UNK]   \n",
              "\n",
              "             9       10      11        12     13     14     15      16  \\\n",
              "input   spartan  ##burg  county  deputies    say      a  woman  [MASK]   \n",
              "target    [UNK]   [UNK]   [UNK]     [UNK]  [UNK]  [UNK]  [UNK]      is   \n",
              "\n",
              "                17     18     19     20       21      22     23     24  \\\n",
              "input   recovering  after  being   shot  several  [MASK]     by    her   \n",
              "target       [UNK]  [UNK]  [UNK]  [UNK]    [UNK]   times  [UNK]  [UNK]   \n",
              "\n",
              "               25      26         27     28     29            30     31  \\\n",
              "input   boyfriend  sunday  afternoon      .  [SEP]  construction     on   \n",
              "target      [UNK]   [UNK]      [UNK]  [UNK]  [UNK]         [UNK]  [UNK]   \n",
              "\n",
              "           32     33      34       35       36      37     38        39  \\\n",
              "input     the      $  [MASK]  million  project  [MASK]    now  expected   \n",
              "target  [UNK]  [UNK]      26    [UNK]    [UNK]      is  [UNK]     [UNK]   \n",
              "\n",
              "           40     41     42      43      44     45     46     47      48  \\\n",
              "input      to  begin  early  [MASK]  spring      -      -  about  [MASK]   \n",
              "target  [UNK]  [UNK]  [UNK]    next   [UNK]  [UNK]  [UNK]  [UNK]     six   \n",
              "\n",
              "            49            50     51     52        53      54     55     56  \\\n",
              "input   months  connectivity   than  first    [MASK]  [MASK]      -   with   \n",
              "target   [UNK]         later  [UNK]  [UNK]  forecast       -  [UNK]  [UNK]   \n",
              "\n",
              "           57      58     59      60     61      62     63     64     65  \\\n",
              "input       o  [MASK]   ##up  ##ancy     of  [MASK]    ##s     by    the   \n",
              "target  [UNK]    ##cc  [UNK]   [UNK]  [UNK]  rental  [UNK]  [UNK]  [UNK]   \n",
              "\n",
              "           66     67     68     69     70  \n",
              "input     end      .      .      .  [SEP]  \n",
              "target  [UNK]  [UNK]  [UNK]  [UNK]  [UNK]  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xb, yb, nsp_targets = get_batch('train')\n",
        "tokenizer.decode(xb['input_ids'][0]), tokenizer.decode(yb[0]), yb.shape\n",
        "print(nsp_targets)\n",
        "\n",
        "input = [[tokenizer.decode([id]) for id in x] for x in xb['input_ids']]\n",
        "target = [[tokenizer.decode([id]) for id in x] for x in yb]\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "df = pd.DataFrame({\"input\": input[0], \"target\": target[0]})\n",
        "df.T\n",
        "# for t1, t2 in zip(xb['input_ids'][0], yb[0]):\n",
        "#   if t2 == -1:\n",
        "#     print(tokenizer.decode([t1]))\n",
        "#   else:\n",
        "#     print(f'{tokenizer.decode([t1])} => {tokenizer.decode([t2])}')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vkZGdaQzGACu"
      },
      "source": [
        "### Simple Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "89x4agmaGMlr"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    # each token directly reads off the logits for the next token from a lookup table\n",
        "    self.word_embedding_table = nn.Embedding(vocab_size, 64)\n",
        "    self.lm_head = nn.Linear(64, vocab_size, bias=False)\n",
        "    self.lm_head.weight = self.word_embedding_table.weight\n",
        "    self.mask_token_id = tokenizer.mask_token_id\n",
        "\n",
        "  def forward(self, x, targets=None):\n",
        "    embedding = self.word_embedding_table(x['input_ids']) # (B, T, C)\n",
        "    logits = self.lm_head(embedding)\n",
        "\n",
        "    if targets is None:\n",
        "      return logits\n",
        "    else:\n",
        "      return logits, F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-100)\n",
        "\n",
        "  def predict(self, x):\n",
        "    idx = x['input_ids'] # (B, T)\n",
        "    x['input_ids'] = torch.concat((torch.zeros(idx.shape[0], 1), idx[:, :-1]), dim=1).long()\n",
        "    logits = self(x) # (B, T, C)\n",
        "    mask = idx == self.mask_token_id # (B, T)\n",
        "    probs = F.softmax(logits[mask], dim=-1) # (T_masked, C)\n",
        "    # idx_masked = torch.multinomial(probs, num_samples=1) # (B, T_masked)\n",
        "    top_probs = torch.topk(probs, 3, dim=-1) # (T_masked, 3)\n",
        "    res = []\n",
        "    for i in range(3):\n",
        "      idx = idx.detach().clone() # (B, T)\n",
        "      idx[mask] = top_probs.indices[:, i].view(-1)\n",
        "      res.append(idx)\n",
        "    res = torch.stack(res)\n",
        "    res = res.permute(1, 0, 2)\n",
        "\n",
        "    return res # (3, B, T)\n",
        "    #  want (B, 3, T)\n",
        "\n",
        "model = SimpleModel(tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KPNKXqz8yYl",
        "outputId": "86ee1e31-c1e9-403c-a575-68c95c44377f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 71, 30522]) torch.Size([])\n",
            "tensor(70.4512, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "logits, loss = model(xb, yb)\n",
        "print(logits.shape, loss.shape)\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMEVbP8UUTLS",
        "outputId": "dc4059d9-cd04-4e3e-ddff-95e448ca0677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 3, 20]),\n",
              " [\"[CLS] i'm afraid to tell tell male bosses i'm m [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
              "  \"[CLS] i'm afraid to tell fleet male bosses i'm crack [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
              "  \"[CLS] i'm afraid to tell hilary male bosses i'm bryn [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\"],\n",
              " ['[CLS] the truth is that tiger has been a nicerr than he has received credit for. [SEP]',\n",
              "  '[CLS] the truth is that tiger has been a nicer dreamed than he has received credit for. [SEP]',\n",
              "  '[CLS] the truth is that tiger has been a nicer regaining than he has received credit for. [SEP]'])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [\"I'm Afraid to Tell [MASK] Male Bosses I'm [MASK]\",\n",
        "     \"The truth is that Tiger has been a nicer [MASK] than he has received credit for.\"]\n",
        "x = tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "pred = model.predict(x)\n",
        "pred.shape, tokenizer.batch_decode(pred[0]), tokenizer.batch_decode(pred[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1kZbPvtC31q",
        "outputId": "b415758c-1bb9-4a26-cf85-c36ef0437295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2, 1, 0],\n",
            "        [1, 3, 2],\n",
            "        [2, 3, 1],\n",
            "        [3, 2, 1]])\n",
            "tensor([2, 1, 2, 3])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[  101,  1045,  1005,  1049,  4452,  2000,  2425,     2,  3287, 23029,\n",
              "          1045,  1005,  1049,     1,   102],\n",
              "        [  101,  1045,  1005,  1049,  4452,  2000,  2425,     2,  3287, 23029,\n",
              "          1045,  1005,  1049,     3,   102]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [\"I'm Afraid to Tell [MASK] Male Bosses I'm [MASK]\", \"I'm Afraid to Tell [MASK] Male Bosses I'm [MASK]\"]\n",
        "x = tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "idx = x['input_ids']\n",
        "mask = idx == tokenizer.mask_token_id\n",
        "# print(mask.shape)\n",
        "logits = torch.randn(2, 15, 4)\n",
        "# print(logits[mask].shape)\n",
        "probs = F.softmax(logits[mask], dim=-1) # (T_masked, C)\n",
        "top_probs = torch.topk(probs, 3, dim=-1) #(T_masked, C)\n",
        "# print(idx[mask].shape)\n",
        "print(top_probs.indices)\n",
        "idx[mask] = top_probs.indices[:, 0].view(-1)\n",
        "print(top_probs.indices[:, 0].view(-1))\n",
        "idx\n",
        "# idx[mask].shape\n",
        "# pred = model.predict(x)\n",
        "# tokenizer.batch_decode(pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8EmKwwRfGNot"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYfxu7vMKAQP",
        "outputId": "e41347fd-9bd6-4556-cb1e-ff3b64f4d463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 8]), torch.Size([4, 8, 32]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape\n",
        "\n",
        "logits = torch.randn((B, T, T))\n",
        "attn = F.softmax(logits, dim=-1)\n",
        "print(attn.sum(dim=-1)) # probs sum to 1 for each token/row\n",
        "res = attn @ x\n",
        "attn.shape, res.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F76fBg8A3VBt",
        "outputId": "80b8d956-7541-4cbc-ec54-fdd5216d1b03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for self-attention, logits come from x\n",
        "logits = x @ x.transpose(-1, -2) # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
        "\n",
        "logits2 = []\n",
        "for i in range(B):\n",
        "  logits_b = []\n",
        "  for j in range(T):\n",
        "    logits_b.append(x[i, j] @ x[i].T) # (, C) @ (C, T) ---> (, T)\n",
        "\n",
        "  logits2.append(torch.stack(logits_b)) # (T, T)\n",
        "logits2 = torch.stack(logits2)\n",
        "\n",
        "torch.allclose(logits, logits2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCZUZVJe8tFN",
        "outputId": "3fafbf45-47b5-40ca-d964-4501c8675685"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 32])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "key = nn.Linear(C, C, bias=False)\n",
        "query = nn.Linear(C, C, bias=False)\n",
        "value = nn.Linear(C, C, bias=False)\n",
        "q = query(x)\n",
        "k = key(x)\n",
        "v = value(x)\n",
        "\n",
        "logits = q @ k.transpose(-1, -2) # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
        "attn = F.softmax(logits, dim=-1)\n",
        "res = attn @ v # (B, T, T) @ (B, T, C)\n",
        "res.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FyZU7PDI-XMj"
      },
      "source": [
        "Multi-head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRXRNIUyCz1y",
        "outputId": "57a088f4-0578-4e56-bdb7-2ce4f564736b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 32])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "H = 2\n",
        "C_H = C // H\n",
        "q_h = q.view(B, T, H, -1).transpose(1, 2)\n",
        "k_h = k.view(B, T, H, -1).transpose(1, 2)\n",
        "# logits = torch.randn((B, H, T, T))\n",
        "logits = q_h @ k_h.transpose(-1, -2) # (B, H, T, C_H) @ (B, H, C_H, T) ---> (B, H, T, T)\n",
        "attn = F.softmax(logits, dim=-1)\n",
        "v_h = v.view(B, T, H, -1).transpose(1, 2)\n",
        "res = attn @ v_h # (B, H, T, T) @ (B, H, T, C/H) ---> (B, H, T, C/H)\n",
        "res.shape\n",
        "res.transpose(1, 2).reshape(B, T, -1).shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6MRmb52VP8Di"
      },
      "source": [
        "Scaled: formular Var(aX), Var(X+Y) and Var(XY) in https://en.wikipedia.org/wiki/Variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP1KeDj0Q1fE",
        "outputId": "eb7b8a0f-1616-419c-b40a-eae911c0527a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
            "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
          ]
        }
      ],
      "source": [
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1))\n",
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * 8, dim=-1))\n",
        "\n",
        "# Increasing the variance of the logits makes the probs moving to more peaky,\n",
        "# coverging to one hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT2QyhCrzhMX",
        "outputId": "8698b2fe-59e2-42c3-8d76-b6c1c941a8a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.9592) tensor(0.9445) tensor(0.8309)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(93.2930)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = torch.randn(100)\n",
        "q = torch.randn(100)\n",
        "prod = k * q\n",
        "print(k.var(), q.var(), prod.var()) # var(XY) = 1\n",
        "\n",
        "k = torch.randn(T, 100)\n",
        "q = torch.randn(T, 100)\n",
        "logits = q @ k.T\n",
        "logits.var() # var(X+Y) = 2*var(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfAWAJ6JzEyk",
        "outputId": "59452585-7871-4f43-de96-6e5d4319cc14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.2408)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = torch.randn(B,T,C_H)\n",
        "q = torch.randn(B,T,C_H)\n",
        "# var(k @ q.T) = C_H * var(k)\n",
        "# var(k @ q.T * x) = C_H * var(k) * x^2\n",
        "# x^2 = 1/C_H\n",
        "wei = q @ k.transpose(-2, -1) * C_H**-0.5\n",
        "wei.var()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rc1lYtKpKB0f"
      },
      "source": [
        "### Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iPqnpb1UaaRb"
      },
      "outputs": [],
      "source": [
        "# BertModel\n",
        "#   word_embedding, pos_emdding, tk_type_emdding\n",
        "#   BertLayer *\n",
        "#     SelfAttention\n",
        "#     mlp\n",
        "#   cls_head\n",
        "#   lm_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "torch.isin(a, torch.tensor([1]))\n",
        "tokenizer.all_special_ids\n",
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vAeX18EL6pkp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.019874 M parameters\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 189\u001b[0m\n\u001b[1;32m    185\u001b[0m         lm_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    186\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m--> 189\u001b[0m train()\n",
            "Cell \u001b[0;32mIn[6], line 173\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[1;32m    171\u001b[0m     \u001b[39m# every once in a while evaluate the loss on train and val sets\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m%\u001b[39m eval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m==\u001b[39m max_iters \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 173\u001b[0m         losses \u001b[39m=\u001b[39m estimate_loss()\n\u001b[1;32m    174\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m    175\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39miter\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: train loss nsp=\u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m lm=\u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, val loss nsp=\u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m lm=\u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    178\u001b[0m     \u001b[39m# sample a batch of data\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "Cell \u001b[0;32mIn[6], line 153\u001b[0m, in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m         _, _, nsp_loss, lm_loss \u001b[39m=\u001b[39m model(X, nsp_targets\u001b[39m=\u001b[39mnsp_targets, lm_targets\u001b[39m=\u001b[39mY)\n\u001b[1;32m    152\u001b[0m         nsp_losses[k] \u001b[39m=\u001b[39m nsp_loss\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m nsp_loss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 153\u001b[0m         lm_losses[k] \u001b[39m=\u001b[39m lm_loss\u001b[39m.\u001b[39;49mitem() \u001b[39mif\u001b[39;00m lm_loss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    154\u001b[0m     out[split] \u001b[39m=\u001b[39m nsp_losses\u001b[39m.\u001b[39mmean(), lm_losses\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    155\u001b[0m model\u001b[39m.\u001b[39mtrain()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "hidden_size = 32\n",
        "num_head = 4\n",
        "drop_out = 0.0\n",
        "num_layers = 2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "max_iters = 60_000\n",
        "eval_interval = 100\n",
        "lr = 1e-4\n",
        "eval_iters = 200\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "counts = Counter()\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.head_size = hidden_size // num_head\n",
        "\n",
        "        self.query = nn.Linear(hidden_size, hidden_size)\n",
        "        self.key = nn.Linear(hidden_size, hidden_size)\n",
        "        self.value = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(drop_out)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        k = k.view(B, T, num_head, -1).transpose(1, 2)  # (B, num_head, T, head_size)\n",
        "        v = self.value(x)\n",
        "        v = v.view(B, T, num_head, -1).transpose(1, 2)  # (B, num_head, T, head_size)\n",
        "        q = self.query(x)\n",
        "        q = q.view(B, T, num_head, -1).transpose(1, 2)  # (B, num_head, T, head_size)\n",
        "\n",
        "        logits = q @ k.transpose(-1, -2) / self.head_size**0.5\n",
        "        mask = mask[:, None, None, :]  # (bs, 1, 1, seq_len)\n",
        "        logits = logits.masked_fill(mask == 0, float(\"-inf\"))\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        probs = self.dropout(probs)\n",
        "        res = probs @ v  # (B, num_head, T, head_size)\n",
        "        res = res.transpose(1, 2).reshape(B, T, -1)  # (B, T, C)\n",
        "        return self.dropout(self.dense(res))  # (B, T, C)\n",
        "\n",
        "\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sa = SelfAttention()\n",
        "        self.ffwd = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 4 * hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * hidden_size, hidden_size),\n",
        "            nn.Dropout(drop_out),\n",
        "        )\n",
        "        self.ln1 = nn.LayerNorm(hidden_size)\n",
        "        self.ln2 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = x + self.sa(self.ln1(x), mask)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class BertModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.word_embedding = nn.Embedding(\n",
        "            tokenizer.vocab_size, hidden_size, padding_idx=tokenizer.pad_token_id\n",
        "        )\n",
        "        self.pos_embedding = nn.Embedding(tokenizer.model_max_length, hidden_size)\n",
        "        self.tk_type_embedding = nn.Embedding(2, hidden_size)\n",
        "        position_ids = torch.arange(tokenizer.model_max_length).unsqueeze(0)\n",
        "        self.register_buffer(\"position_ids\", position_ids)\n",
        "        self.dropout = nn.Dropout(drop_out)\n",
        "        self.ln = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self.bert_layers = nn.ModuleList([BertLayer() for _ in range(num_layers)])\n",
        "        self.ln_final = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self.cls_dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.cls_af = nn.Tanh()\n",
        "        self.cls_head = nn.Linear(hidden_size, 2)\n",
        "\n",
        "        self.lm_ln = nn.LayerNorm(hidden_size)\n",
        "        self.lm_head = nn.Linear(hidden_size, tokenizer.vocab_size, bias=False)\n",
        "        self.lm_head.weight = self.word_embedding.weight\n",
        "\n",
        "    def forward(self, encoding, nsp_targets=None, lm_targets=None):\n",
        "        ids = encoding[\"input_ids\"]  # (B, T)\n",
        "        type_ids = encoding[\"token_type_ids\"]\n",
        "        atten_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "        B, T = ids.shape\n",
        "        word_embedding = self.word_embedding(ids)\n",
        "        pos_ids = self.position_ids[:, :T]\n",
        "        pos_embedding = self.pos_embedding(pos_ids)\n",
        "        tk_type_embedding = self.tk_type_embedding(type_ids)\n",
        "        embedding = word_embedding + pos_embedding + tk_type_embedding\n",
        "        embedding = self.dropout(self.ln(embedding))\n",
        "\n",
        "        for bert_layer in self.bert_layers:\n",
        "            embedding = bert_layer(embedding, atten_mask)\n",
        "        embedding = self.ln_final(embedding)\n",
        "\n",
        "        cls_logit = self.cls_dense(embedding[:, 0])\n",
        "        cls_logit = self.cls_head(self.cls_af(cls_logit))\n",
        "        lm_logits = self.lm_head(embedding)\n",
        "\n",
        "        cls_loss = None\n",
        "        if nsp_targets is not None:\n",
        "            cls_loss = F.cross_entropy(cls_logit, nsp_targets)\n",
        "\n",
        "        lm_loss = None\n",
        "        if lm_targets is not None:\n",
        "            lm_loss = F.cross_entropy(\n",
        "                lm_logits.view(-1, lm_logits.size(-1)),\n",
        "                lm_targets.view(-1),\n",
        "                ignore_index=-100,\n",
        "            )\n",
        "\n",
        "        return cls_logit, lm_logits, cls_loss, lm_loss\n",
        "\n",
        "    def predict(self, encoding):\n",
        "        cls_logit, lm_logits, _, _ = self(encoding)  # (B, 1) (B, T, C)\n",
        "        probs = F.softmax(lm_logits, dim=-1)  # (B, T, C)\n",
        "        top_probs = torch.topk(probs, 3, dim=-1)  # (B, T, 3)\n",
        "\n",
        "        nsp = F.softmax(cls_logit, dim=-1)\n",
        "\n",
        "        #  (B, 3, T), (B, 2)\n",
        "        return top_probs.indices.transpose(1, 2), nsp\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        nsp_losses = torch.zeros(eval_iters)\n",
        "        lm_losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y, nsp_targets = get_batch(split)\n",
        "            _, _, nsp_loss, lm_loss = model(X, nsp_targets=nsp_targets, lm_targets=Y)\n",
        "            nsp_losses[k] = nsp_loss.item() if nsp_loss is not None else 0\n",
        "            lm_losses[k] = lm_loss.item() if lm_loss is not None else 0\n",
        "        out[split] = nsp_losses.mean(), lm_losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "model = BertModel()\n",
        "model = model.to(device)\n",
        "print(sum(p.numel() for p in model.parameters()) / 1e6, \"M parameters\")\n",
        "# for n, p in model.named_parameters():\n",
        "#   print(n, p.numel()/1e6, 'M')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train():\n",
        "    for iter in range(max_iters):\n",
        "        # every once in a while evaluate the loss on train and val sets\n",
        "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "            losses = estimate_loss()\n",
        "            print(\n",
        "                f\"step {iter}: train loss nsp={losses['train'][0]:.4f} lm={losses['train'][1]:.4f}, val loss nsp={losses['val'][0]:.4f} lm={losses['val'][1]:.4f}\"\n",
        "            )\n",
        "\n",
        "        # sample a batch of data\n",
        "        xb, yb, nsp_targets = get_batch(\"train\")\n",
        "\n",
        "        # evaluate the loss\n",
        "        _, _, nsp_loss, lm_loss = model(xb, lm_targets=yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # loss = nsp_loss + lm_loss\n",
        "        lm_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('e t o a i n h s r l d u m w y c g, f p',\n",
              " Counter({1041: 960,\n",
              "          1056: 693,\n",
              "          1051: 668,\n",
              "          1037: 618,\n",
              "          1045: 509,\n",
              "          1050: 506,\n",
              "          1044: 502,\n",
              "          1055: 492,\n",
              "          1054: 476,\n",
              "          1048: 320,\n",
              "          1040: 292,\n",
              "          1057: 272,\n",
              "          1049: 237,\n",
              "          1059: 207,\n",
              "          1061: 203,\n",
              "          1039: 203,\n",
              "          1043: 181,\n",
              "          1010: 181,\n",
              "          1042: 175,\n",
              "          1052: 136,\n",
              "          1038: 115,\n",
              "          1024: 105,\n",
              "          1047: 87,\n",
              "          1012: 72,\n",
              "          1058: 63,\n",
              "          1005: 45,\n",
              "          1029: 24,\n",
              "          1025: 22,\n",
              "          999: 13,\n",
              "          1011: 10,\n",
              "          1060: 10,\n",
              "          1062: 9,\n",
              "          1046: 6,\n",
              "          1053: 5}))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode([token for token, count in counts.most_common(20)]), counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "Qws1z_gkNgnU",
        "outputId": "ad376218-e8e7-4824-89f7-17248313f205"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'get_batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m500\u001b[39m)\n\u001b[1;32m      3\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_columns\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m500\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m xb, yb, nsp_targets \u001b[39m=\u001b[39m get_batch(\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m [[tokenizer\u001b[39m.\u001b[39mdecode([\u001b[39mid\u001b[39m]) \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m xb[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      7\u001b[0m target \u001b[39m=\u001b[39m [[tokenizer\u001b[39m.\u001b[39mdecode([\u001b[39mid\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m y] \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m yb]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_batch' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "xb, yb, nsp_targets = get_batch('train')\n",
        "input = [[tokenizer.decode([id]) for id in x] for x in xb['input_ids']]\n",
        "target = [[tokenizer.decode([id]) if id != -100 else \"\" for id in y] for y in yb]\n",
        "# model(xb, lm_targets=yb)\n",
        "pred, nsp = model.predict(xb)\n",
        "\n",
        "print(xb['input_ids'].shape, yb.shape, pred.shape)\n",
        "# print(xb['input_ids'][0])\n",
        "# print(yb[0])\n",
        "# print(xb['token_type_ids'][0])\n",
        "# print(xb['attention_mask'][0])\n",
        "\n",
        "pred_list = [[[tokenizer.decode([id]) if yid != -100 else \"\" for id, yid in zip(p, y)] for p in p3] for p3, y in zip(pred, yb)]\n",
        "# len(input), len(target), len(pred_list)\n",
        "df = pd.DataFrame({'input': input[0], 'target': target[0],\n",
        "                   'pred1': pred_list[0][0], # (B, rank)\n",
        "                   'pred2': pred_list[0][1],\n",
        "                   'pred3': pred_list[0][2]})\n",
        "df.T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "pv0gtpN4ZS7G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
              "        [-100, -100, -100,  ..., -100, -100, -100],\n",
              "        [-100, -100, -100,  ..., -100, -100, -100],\n",
              "        ...,\n",
              "        [-100, -100, -100,  ..., -100, -100, -100],\n",
              "        [-100, -100, 2698,  ..., -100, -100, -100],\n",
              "        [-100, -100, -100,  ..., -100, -100, -100]])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xb, yb, nsp = get_batch('train')\n",
        "yb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNj3Mh9qocpJXm8VX98pxvd",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00df2531c1964177912eda85ff390b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3698ed92044b15bf6a1add32c59151",
            "placeholder": "​",
            "style": "IPY_MODEL_7d92183a905345d7893b16afd52bff98",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "0150e70c287e41a7aa63f4b311a4fb20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03e8910cec704b9faf3785419a074d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61bb426559ab4a26a03616f919d3f5e7",
            "placeholder": "​",
            "style": "IPY_MODEL_cea3af583b07467d8d0d780be52bffb0",
            "value": " 570/570 [00:00&lt;00:00, 7.58kB/s]"
          }
        },
        "0a75ebb318994fef87c5245d76386b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16fa3a6d20d44b748755c6559988ee29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bf9a5c56b9c45f3988298bfe23ffbeb",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52c8091c5a91410884c4cc4eb63ab664",
            "value": 570
          }
        },
        "194b763975f94027933438a9f61db312": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fdc3f2bc066456181a119e2626253f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a70a4070369943d786c5f6419bc7855e",
              "IPY_MODEL_16fa3a6d20d44b748755c6559988ee29",
              "IPY_MODEL_03e8910cec704b9faf3785419a074d51"
            ],
            "layout": "IPY_MODEL_194b763975f94027933438a9f61db312"
          }
        },
        "27d788ede01d4a63ba5623947dfcc610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d1e130563a4d8d9899a2c172ac0b7e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a75ebb318994fef87c5245d76386b7c",
            "value": " 28.0/28.0 [00:00&lt;00:00, 299B/s]"
          }
        },
        "44823a0f1dc745b797344c864dcaf9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c8091c5a91410884c4cc4eb63ab664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ba53621b5404299b4bccd0ecc793b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738470260044459c88f2fcab1601601c",
            "placeholder": "​",
            "style": "IPY_MODEL_e1c54fb227ff4c4dbdd71e71beffc60e",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "61bb426559ab4a26a03616f919d3f5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bf9a5c56b9c45f3988298bfe23ffbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c47f2dd4a8b42d5aac221e1f1d9e49a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738470260044459c88f2fcab1601601c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d92183a905345d7893b16afd52bff98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d8b6965c49b4de8a00d6353ca5ce3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44823a0f1dc745b797344c864dcaf9ab",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cff6d96ada8f4abc95f2c9309abd9fdd",
            "value": 231508
          }
        },
        "90d1e130563a4d8d9899a2c172ac0b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3698ed92044b15bf6a1add32c59151": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a70a4070369943d786c5f6419bc7855e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce6194ae648140c7b78029418bdfa9ef",
            "placeholder": "​",
            "style": "IPY_MODEL_c39d642238cc49d8b9de1586b3e2cd53",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ba4df94adffa4420818c508ef5f7845a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00df2531c1964177912eda85ff390b44",
              "IPY_MODEL_e76b393bc34f4b55a738acc581c363ae",
              "IPY_MODEL_27d788ede01d4a63ba5623947dfcc610"
            ],
            "layout": "IPY_MODEL_eb4d44035640476b8814a7bbd191bd8a"
          }
        },
        "bb31d174d5b9436084d67a8d02ee7cba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c39d642238cc49d8b9de1586b3e2cd53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce6194ae648140c7b78029418bdfa9ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea3af583b07467d8d0d780be52bffb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cff6d96ada8f4abc95f2c9309abd9fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d482d6cd9cc542e0b96c5223f24ac632": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c54fb227ff4c4dbdd71e71beffc60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e76b393bc34f4b55a738acc581c363ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d482d6cd9cc542e0b96c5223f24ac632",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f101c3efd4f044349897ac02ef3ecf2b",
            "value": 28
          }
        },
        "e7c3b0369c7e48849f3328bf066975cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ba53621b5404299b4bccd0ecc793b4f",
              "IPY_MODEL_8d8b6965c49b4de8a00d6353ca5ce3d0",
              "IPY_MODEL_fc323784e2f7494d93425704d21a0643"
            ],
            "layout": "IPY_MODEL_6c47f2dd4a8b42d5aac221e1f1d9e49a"
          }
        },
        "eb4d44035640476b8814a7bbd191bd8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f101c3efd4f044349897ac02ef3ecf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc323784e2f7494d93425704d21a0643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb31d174d5b9436084d67a8d02ee7cba",
            "placeholder": "​",
            "style": "IPY_MODEL_0150e70c287e41a7aa63f4b311a4fb20",
            "value": " 232k/232k [00:00&lt;00:00, 3.93MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
