{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zanqi/tinybert/blob/main/bert_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kC7VRPdCFlLf"
      },
      "source": [
        "### Getting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc5qXnJ8tf6a",
        "outputId": "37169772-fbea-454a-a057-e62b7d0ff251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-07-13 01:45:48--  https://raw.githubusercontent.com/zanqi/tinybert/main/news.tsv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10694395 (10M) [application/zip]\n",
            "Saving to: ‘news.tsv.zip’\n",
            "\n",
            "news.tsv.zip        100%[===================>]  10.20M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-07-13 01:45:48 (115 MB/s) - ‘news.tsv.zip’ saved [10694395/10694395]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the MIND dataset\n",
        "!wget https://raw.githubusercontent.com/zanqi/tinybert/main/news.tsv.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O shakespeare.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIL6IVSTgHyy",
        "outputId": "e525ce5b-23dd-4b00-850f-6fe023dd27e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  news.tsv.zip\n",
            "  inflating: news.tsv                \n"
          ]
        }
      ],
      "source": [
        "! unzip {'news.tsv.zip'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYEVguyIxRkU",
        "outputId": "760cfd43-74e2-479a-a498-ebf4400483a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (4.31.0)\n",
            "Requirement already satisfied: nltk in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (3.8.1)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.0.3-cp39-cp39-macosx_11_0_arm64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 6.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (1.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: filelock in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: click in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from nltk) (1.3.1)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[K     |████████████████████████████████| 502 kB 4.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
            "Collecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[K     |████████████████████████████████| 341 kB 2.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.0.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/zanqiliang/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tzdata, pytz, pandas\n",
            "Successfully installed pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip3 install transformers nltk pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUba-f4ytoUZ",
        "outputId": "ca1bd3a6-f345-4d94-89b7-7e303ca46240"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/zanqiliang/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "    \n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZYqD6ivcuOHj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zanqiliang/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/zanqiliang/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "with open('shakespeare.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "sents = nltk.sent_tokenize(text) # list(str)\n",
        "\n",
        "n = len(sents)\n",
        "train_data = sents[:int(n*0.9)]\n",
        "val_data = sents[int(n*0.9):]\n",
        "\n",
        "#shakespeare\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data), (batch_size,))\n",
        "    sents1 = [data[i] for i in ix]\n",
        "    x = tokenizer(sents1, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    token_ids = torch.LongTensor(x[\"input_ids\"])\n",
        "    attention_mask = torch.LongTensor(x[\"attention_mask\"])\n",
        "    special = torch.isin(token_ids, torch.tensor(tokenizer.all_special_ids))\n",
        "    mask = torch.rand(token_ids.shape) < 0.15\n",
        "    \n",
        "    mask = mask & (attention_mask == 1) & ~special\n",
        "    mask_mask = (torch.rand(token_ids.shape) < 0.8) & mask\n",
        "    mask_rand = (torch.rand(token_ids.shape) < 0.5) & mask & ~mask_mask\n",
        "\n",
        "    y = token_ids.detach().clone()\n",
        "    y[~mask] = -100\n",
        "    counts.update(y[y != -100].tolist())\n",
        "\n",
        "    token_ids[mask_mask] = tokenizer.mask_token_id\n",
        "    token_ids[mask_rand] = torch.randint(\n",
        "        tokenizer.vocab_size, token_ids[mask_rand].shape\n",
        "    )\n",
        "\n",
        "    return x.to(device), y.to(device), None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('news.tsv',header=None,sep='\\t')\n",
        "\n",
        "data.columns=['News ID',\n",
        "\"Category\",\n",
        "\"SubCategory\",\n",
        "\"Title\",\n",
        "\"Abstract\",\n",
        "\"URL\",\n",
        "\"Title Entities\",\n",
        "\"Abstract Entities \"]\n",
        "\n",
        "text_data = data.iloc[:, 3:5]\n",
        "text_data.Abstract.str.len().describe()\n",
        "\n",
        "# abstracts = text_data.Abstract\n",
        "sents_by_abstract = [nltk.sent_tokenize(a) for a in text_data[text_data.Abstract.str.len() > 10].Abstract]\n",
        "abstracts = [sents for sents in sents_by_abstract if len(sents) > 1]\n",
        "# len(abstracts), abstracts[:10]\n",
        "\n",
        "zipped = [zip(a, a[1:]) for a in abstracts]\n",
        "pairs = [(s1, s2) for z in zipped for s1, s2 in z]\n",
        "\n",
        "n = int(0.9*len(pairs)) # first 90% will be train, rest val\n",
        "train_data = pairs[:n]\n",
        "val_data = pairs[n:]\n",
        "\n",
        "# news\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data), (batch_size,))\n",
        "    ix_mask = torch.rand(batch_size) < 0.5\n",
        "    next_ix = ix.detach().clone()\n",
        "    next_ix[ix_mask] = (ix[ix_mask] + 10) % len(data)\n",
        "    sents1 = [\"\".join(data[i]) for i in ix]\n",
        "    # sents1 = [\"\".join(data[i][: len(data[i]) // 2]) for i in ix]\n",
        "    # sents2 = [\"\".join(data[i][len(data[i]) // 2 :]) for i in next_ix]\n",
        "    # x = tokenizer(sents1, sents2, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    x = tokenizer(sents1, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    token_ids = torch.LongTensor(x[\"input_ids\"])\n",
        "    attention_mask = torch.LongTensor(x[\"attention_mask\"])\n",
        "    special = torch.isin(token_ids, torch.tensor(tokenizer.all_special_ids))\n",
        "    mask = torch.rand(token_ids.shape) < 0.15\n",
        "    most_common = torch.isin(\n",
        "        token_ids, torch.tensor(counts.most_common(len(counts) // 20))\n",
        "    )\n",
        "    mask = mask & (attention_mask == 1) & ~special & ~most_common\n",
        "    # mask = mask & (attention_mask == 1) & ~special\n",
        "    mask_mask = (torch.rand(token_ids.shape) < 0.8) & mask\n",
        "    mask_rand = (torch.rand(token_ids.shape) < 0.5) & mask & ~mask_mask\n",
        "\n",
        "    y = token_ids.detach().clone()\n",
        "    y[~mask] = -100\n",
        "    counts.update(y[y != -100].tolist())\n",
        "\n",
        "    token_ids[mask_mask] = tokenizer.mask_token_id\n",
        "    token_ids[mask_rand] = torch.randint(\n",
        "        tokenizer.vocab_size, token_ids[mask_rand].shape\n",
        "    )\n",
        "\n",
        "    nsp_target = ix == next_ix\n",
        "    return x.to(device), y.to(device), nsp_target.long().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "VjUv3VFCrm5R",
        "outputId": "8ec8a10d-8809-4569-a8ae-50be4713417d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Real talk. Demi Moore got candid about a variety of topics in her new book, Inside Out, including her famous exes, substance abuse struggles and her heartbreaking sexual assault. \"The same question kept going through my head: How did I get here?\" the 56-year-old actress began in the memoir, which was released on Tuesday, September 24. \"The husband who I\\'d thought was the love of my life had cheated on me and then decided he didn\\'t want to work on our marriage. My children weren\\'t speaking me. … Is this life? I wondered. Because if this is it, I\\'m done.\" Moore provided insight into all three of her marriages in the book. She was married to Freddy Moore from 1980 to 1985, Bruce Willis from 1987 to 2000 and Ashton Kutcher from 2005 to 2013. The end of the G.I. Jane star\\'s relationship with the former That 70\\'s Show star, however, seemed to have the biggest impact on her. \"I lost me,\" the Ghost actress told Diane Sawyer on Good Morning America on Monday, September 23, about their split. \"I think the thing if I were to look back, I would say I blinded myself and I lost myself.\" Moore and Kutcher, who is 15 years her junior, started dating in 2003. After Us Weekly broke the news that he was allegedly unfaithful in 2011, the twosome called it quits. The Ranch star married Mila Kunis in July 2015. They share two kids: Wyatt, 4, and Dimitri, 2. Kutcher, for his part, reflected on the divorce during an appearance on Dax Shepard\\'s \"Armchair Expert\" podcast last year. \"Right after I got divorced, I went to the mountains for a week by myself,\" Kutcher told Shepard in February 2018. \"I did no food, no drink   just water and tea. I took all my computers away, my phone, my everything. I was there by myself, so there was no talking. I just had a notepad, a pen and water and tea   for a week.\" He referred to the trip as \"really spiritual and kind of awesome.\" \"I wrote down every single relationship that I had where I felt like there was some grudge or some anything, regret, anything,\" Kutcher explained. \"And I wrote letters to every single person, and on day seven, I typed them all out and then sent them.\" While Moore certainly doesn\\'t hold back in Inside Out, a source told Us earlier this month that the Kutcher isn\\'t worried about the book. \"Ashton knew what was coming. He had a heads up on what is in the book,\" the insider said on September 13. \"He\\'s not mad or disappointed. This is Demi\\'s truth, and he always felt sympathetic toward her. He knows her story and that her upbringing was difficult.\" Inside Out is available now. Scroll through for 10 revelations from the book:'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data.iloc[text_data.Abstract.str.len().argmax()].Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UO9X3jPaqd3F",
        "outputId": "eba2e7de-17ae-426e-e509-43c9d4ea2740"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
              "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50 Worst Habits For Belly Fat</td>\n",
              "      <td>These seemingly harmless habits are holding yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
              "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
              "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
              "      <td>They seem harmless, but there's a very good re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51275</th>\n",
              "      <td>Realme takes chunk of India mobile market as S...</td>\n",
              "      <td>Over 400 percent more phones shipped year-on-year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51276</th>\n",
              "      <td>Young Northeast Florida fans flock to U.S. wom...</td>\n",
              "      <td>When the U.S. women's national soccer team arr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51277</th>\n",
              "      <td>Adapting, Learning And Soul Searching: Reflect...</td>\n",
              "      <td>Woolsey Fire Anniversary: A community is forev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51279</th>\n",
              "      <td>St. Dominic soccer player tries to kick cancer...</td>\n",
              "      <td>Sometimes, what happens on the sidelines can b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51280</th>\n",
              "      <td>How the Sounders won MLS Cup</td>\n",
              "      <td>Mark, Jeremiah and Casey were so excited they ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48495 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Title  \\\n",
              "0      The Brands Queen Elizabeth, Prince Charles, an...   \n",
              "1                          50 Worst Habits For Belly Fat   \n",
              "2      The Cost of Trump's Aid Freeze in the Trenches...   \n",
              "3      I Was An NBA Wife. Here's How It Affected My M...   \n",
              "4      How to Get Rid of Skin Tags, According to a De...   \n",
              "...                                                  ...   \n",
              "51275  Realme takes chunk of India mobile market as S...   \n",
              "51276  Young Northeast Florida fans flock to U.S. wom...   \n",
              "51277  Adapting, Learning And Soul Searching: Reflect...   \n",
              "51279  St. Dominic soccer player tries to kick cancer...   \n",
              "51280                       How the Sounders won MLS Cup   \n",
              "\n",
              "                                                Abstract  \n",
              "0      Shop the notebooks, jackets, and more that the...  \n",
              "1      These seemingly harmless habits are holding yo...  \n",
              "2      Lt. Ivan Molchanets peeked over a parapet of s...  \n",
              "3      I felt like I was a fraud, and being an NBA wi...  \n",
              "4      They seem harmless, but there's a very good re...  \n",
              "...                                                  ...  \n",
              "51275  Over 400 percent more phones shipped year-on-year  \n",
              "51276  When the U.S. women's national soccer team arr...  \n",
              "51277  Woolsey Fire Anniversary: A community is forev...  \n",
              "51279  Sometimes, what happens on the sidelines can b...  \n",
              "51280  Mark, Jeremiah and Casey were so excited they ...  \n",
              "\n",
              "[48495 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data[text_data.Abstract.str.len() > 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCdxcMk6s2t8",
        "outputId": "7a2e9b43-75f8-45e0-875b-68a9856dee2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['My name is John E. Doe.', 'Please turn to p. 55.']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_text = nltk.sent_tokenize('My name is John E. Doe. Please turn to p. 55.')\n",
        "sent_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbnDJPixuQP-",
        "outputId": "3cbe92b5-19a2-4a48-8fc9-2031362faf72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in sentences:  74948\n",
            "length of dataset in words:  1427558\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset in sentences: \", sum(len(a) for a in abstracts))\n",
        "print(\"length of dataset in words: \", sum(len(nltk.word_tokenize(s)) for a in abstracts for s in a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "bra6rs5t0V5A",
        "outputId": "8d85ab53-1324-4f00-d398-9231b4628adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Lt. Ivan Molchanets peeked over a parapet of sand bags at the front line of the war in Ukraine.', 'Next to him was an empty helmet propped up to trick snipers, already perforated with multiple holes.')\n",
            "{'input_ids': [[101, 1045, 2371, 2066, 1045, 2001, 1037, 9861, 1010, 1998, 2108, 2019, 6452, 2564, 2134, 1005, 1056, 2393, 2008, 1012, 102], [101, 1999, 2755, 1010, 2009, 3053, 3908, 2033, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"[CLS] i felt like i was a fraud, and being an nba wife didn't help that. [SEP]\",\n",
              " '[CLS] in fact, it nearly destroyed me. [SEP]']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(train_data[0])\n",
        "encoded = tokenizer(train_data[1])\n",
        "print(encoded) # len(token_ids), tokenizer.decode(token_ids)\n",
        "tokenizer.batch_decode(encoded['input_ids'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([54, 23, 93, 26]), tensor([64, 33,  3, 36]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "# random.seed(1337)\n",
        "\n",
        "random.random()\n",
        "ix = torch.randint(100, (4,))\n",
        "mask = torch.rand(4) < 0.5\n",
        "next_ix = ix.detach().clone()\n",
        "next_ix[mask] = (ix[mask] + 10) % 100\n",
        "ix, next_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oKYVYCxpxP4b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "random.seed(1337)\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data), (batch_size,))\n",
        "  ix_mask = torch.rand(batch_size) < 0.5\n",
        "  next_ix = ix.detach().clone()\n",
        "  next_ix[ix_mask] = (ix[ix_mask] + 10) % len(data)\n",
        "  sents1 = [data[i][0] for i in ix]\n",
        "  sents2 = [data[i][1] for i in next_ix]\n",
        "  x = tokenizer(sents1, sents2, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "  token_ids = torch.LongTensor(x[\"input_ids\"])\n",
        "  attention_mask = torch.LongTensor(x[\"attention_mask\"])\n",
        "  cls = token_ids == tokenizer.cls_token_id\n",
        "  sep = token_ids == tokenizer.sep_token_id\n",
        "  special = cls | sep\n",
        "  mask = torch.rand(token_ids.shape) < 0.15\n",
        "  mask = mask & (attention_mask == 1) & ~special\n",
        "  mask_mask = (torch.rand(token_ids.shape) < 0.8) & mask\n",
        "  mask_rand = (torch.rand(token_ids.shape) < 0.5) & mask & ~mask_mask\n",
        "\n",
        "  y = token_ids.detach().clone()\n",
        "  y[~mask] = -100\n",
        "\n",
        "  token_ids[mask_mask] = tokenizer.mask_token_id\n",
        "  token_ids[mask_rand] = torch.randint(\n",
        "      0, tokenizer.vocab_size, token_ids[mask_rand].shape\n",
        "  )\n",
        "\n",
        "  nsp_target = ix == next_ix\n",
        "  return x, y, nsp_target.float().unsqueeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "emNNvihJCS2g",
        "outputId": "e4aa252e-0a31-41ef-a363-4634ba55c319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>input</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>moore</td>\n",
              "      <td>,</td>\n",
              "      <td>sc</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>fox</td>\n",
              "      <td>carolina</td>\n",
              "      <td>)</td>\n",
              "      <td>-</td>\n",
              "      <td>spartan</td>\n",
              "      <td>##burg</td>\n",
              "      <td>county</td>\n",
              "      <td>deputies</td>\n",
              "      <td>say</td>\n",
              "      <td>a</td>\n",
              "      <td>woman</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>recovering</td>\n",
              "      <td>after</td>\n",
              "      <td>being</td>\n",
              "      <td>shot</td>\n",
              "      <td>several</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>by</td>\n",
              "      <td>her</td>\n",
              "      <td>boyfriend</td>\n",
              "      <td>sunday</td>\n",
              "      <td>afternoon</td>\n",
              "      <td>.</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>construction</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>$</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>million</td>\n",
              "      <td>project</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>now</td>\n",
              "      <td>expected</td>\n",
              "      <td>to</td>\n",
              "      <td>begin</td>\n",
              "      <td>early</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>spring</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>about</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>months</td>\n",
              "      <td>connectivity</td>\n",
              "      <td>than</td>\n",
              "      <td>first</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>-</td>\n",
              "      <td>with</td>\n",
              "      <td>o</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>##up</td>\n",
              "      <td>##ancy</td>\n",
              "      <td>of</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>##s</td>\n",
              "      <td>by</td>\n",
              "      <td>the</td>\n",
              "      <td>end</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>[SEP]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>(</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>is</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>times</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>26</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>is</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>next</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>six</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>later</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>forecast</td>\n",
              "      <td>-</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>##cc</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>rental</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[UNK]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0      1      2      3       4      5         6      7      8   \\\n",
              "input   [CLS]  moore      ,     sc  [MASK]    fox  carolina      )      -   \n",
              "target  [UNK]  [UNK]  [UNK]  [UNK]       (  [UNK]     [UNK]  [UNK]  [UNK]   \n",
              "\n",
              "             9       10      11        12     13     14     15      16  \\\n",
              "input   spartan  ##burg  county  deputies    say      a  woman  [MASK]   \n",
              "target    [UNK]   [UNK]   [UNK]     [UNK]  [UNK]  [UNK]  [UNK]      is   \n",
              "\n",
              "                17     18     19     20       21      22     23     24  \\\n",
              "input   recovering  after  being   shot  several  [MASK]     by    her   \n",
              "target       [UNK]  [UNK]  [UNK]  [UNK]    [UNK]   times  [UNK]  [UNK]   \n",
              "\n",
              "               25      26         27     28     29            30     31  \\\n",
              "input   boyfriend  sunday  afternoon      .  [SEP]  construction     on   \n",
              "target      [UNK]   [UNK]      [UNK]  [UNK]  [UNK]         [UNK]  [UNK]   \n",
              "\n",
              "           32     33      34       35       36      37     38        39  \\\n",
              "input     the      $  [MASK]  million  project  [MASK]    now  expected   \n",
              "target  [UNK]  [UNK]      26    [UNK]    [UNK]      is  [UNK]     [UNK]   \n",
              "\n",
              "           40     41     42      43      44     45     46     47      48  \\\n",
              "input      to  begin  early  [MASK]  spring      -      -  about  [MASK]   \n",
              "target  [UNK]  [UNK]  [UNK]    next   [UNK]  [UNK]  [UNK]  [UNK]     six   \n",
              "\n",
              "            49            50     51     52        53      54     55     56  \\\n",
              "input   months  connectivity   than  first    [MASK]  [MASK]      -   with   \n",
              "target   [UNK]         later  [UNK]  [UNK]  forecast       -  [UNK]  [UNK]   \n",
              "\n",
              "           57      58     59      60     61      62     63     64     65  \\\n",
              "input       o  [MASK]   ##up  ##ancy     of  [MASK]    ##s     by    the   \n",
              "target  [UNK]    ##cc  [UNK]   [UNK]  [UNK]  rental  [UNK]  [UNK]  [UNK]   \n",
              "\n",
              "           66     67     68     69     70  \n",
              "input     end      .      .      .  [SEP]  \n",
              "target  [UNK]  [UNK]  [UNK]  [UNK]  [UNK]  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xb, yb, nsp_targets = get_batch('train')\n",
        "tokenizer.decode(xb['input_ids'][0]), tokenizer.decode(yb[0]), yb.shape\n",
        "print(nsp_targets)\n",
        "\n",
        "input = [[tokenizer.decode([id]) for id in x] for x in xb['input_ids']]\n",
        "target = [[tokenizer.decode([id]) for id in x] for x in yb]\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "df = pd.DataFrame({\"input\": input[0], \"target\": target[0]})\n",
        "df.T\n",
        "# for t1, t2 in zip(xb['input_ids'][0], yb[0]):\n",
        "#   if t2 == -1:\n",
        "#     print(tokenizer.decode([t1]))\n",
        "#   else:\n",
        "#     print(f'{tokenizer.decode([t1])} => {tokenizer.decode([t2])}')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vkZGdaQzGACu"
      },
      "source": [
        "### Simple Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "89x4agmaGMlr"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    # each token directly reads off the logits for the next token from a lookup table\n",
        "    self.word_embedding_table = nn.Embedding(vocab_size, 64)\n",
        "    self.lm_head = nn.Linear(64, vocab_size, bias=False)\n",
        "    self.lm_head.weight = self.word_embedding_table.weight\n",
        "    self.mask_token_id = tokenizer.mask_token_id\n",
        "\n",
        "  def forward(self, x, targets=None):\n",
        "    embedding = self.word_embedding_table(x['input_ids']) # (B, T, C)\n",
        "    logits = self.lm_head(embedding)\n",
        "\n",
        "    if targets is None:\n",
        "      return logits\n",
        "    else:\n",
        "      return logits, F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-100)\n",
        "\n",
        "  def predict(self, x):\n",
        "    idx = x['input_ids'] # (B, T)\n",
        "    x['input_ids'] = torch.concat((torch.zeros(idx.shape[0], 1), idx[:, :-1]), dim=1).long()\n",
        "    logits = self(x) # (B, T, C)\n",
        "    mask = idx == self.mask_token_id # (B, T)\n",
        "    probs = F.softmax(logits[mask], dim=-1) # (T_masked, C)\n",
        "    # idx_masked = torch.multinomial(probs, num_samples=1) # (B, T_masked)\n",
        "    top_probs = torch.topk(probs, 3, dim=-1) # (T_masked, 3)\n",
        "    res = []\n",
        "    for i in range(3):\n",
        "      idx = idx.detach().clone() # (B, T)\n",
        "      idx[mask] = top_probs.indices[:, i].view(-1)\n",
        "      res.append(idx)\n",
        "    res = torch.stack(res)\n",
        "    res = res.permute(1, 0, 2)\n",
        "\n",
        "    return res # (3, B, T)\n",
        "    #  want (B, 3, T)\n",
        "\n",
        "model = SimpleModel(tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KPNKXqz8yYl",
        "outputId": "86ee1e31-c1e9-403c-a575-68c95c44377f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 71, 30522]) torch.Size([])\n",
            "tensor(70.4512, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "logits, loss = model(xb, yb)\n",
        "print(logits.shape, loss.shape)\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMEVbP8UUTLS",
        "outputId": "dc4059d9-cd04-4e3e-ddff-95e448ca0677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 3, 20]),\n",
              " [\"[CLS] i'm afraid to tell tell male bosses i'm m [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
              "  \"[CLS] i'm afraid to tell fleet male bosses i'm crack [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
              "  \"[CLS] i'm afraid to tell hilary male bosses i'm bryn [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\"],\n",
              " ['[CLS] the truth is that tiger has been a nicerr than he has received credit for. [SEP]',\n",
              "  '[CLS] the truth is that tiger has been a nicer dreamed than he has received credit for. [SEP]',\n",
              "  '[CLS] the truth is that tiger has been a nicer regaining than he has received credit for. [SEP]'])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [\"I'm Afraid to Tell [MASK] Male Bosses I'm [MASK]\",\n",
        "     \"The truth is that Tiger has been a nicer [MASK] than he has received credit for.\"]\n",
        "x = tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "pred = model.predict(x)\n",
        "pred.shape, tokenizer.batch_decode(pred[0]), tokenizer.batch_decode(pred[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1kZbPvtC31q",
        "outputId": "b415758c-1bb9-4a26-cf85-c36ef0437295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2, 1, 0],\n",
            "        [1, 3, 2],\n",
            "        [2, 3, 1],\n",
            "        [3, 2, 1]])\n",
            "tensor([2, 1, 2, 3])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[  101,  1045,  1005,  1049,  4452,  2000,  2425,     2,  3287, 23029,\n",
              "          1045,  1005,  1049,     1,   102],\n",
              "        [  101,  1045,  1005,  1049,  4452,  2000,  2425,     2,  3287, 23029,\n",
              "          1045,  1005,  1049,     3,   102]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [\"I'm Afraid to Tell [MASK] Male Bosses I'm [MASK]\", \"I'm Afraid to Tell [MASK] Male Bosses I'm [MASK]\"]\n",
        "x = tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "idx = x['input_ids']\n",
        "mask = idx == tokenizer.mask_token_id\n",
        "# print(mask.shape)\n",
        "logits = torch.randn(2, 15, 4)\n",
        "# print(logits[mask].shape)\n",
        "probs = F.softmax(logits[mask], dim=-1) # (T_masked, C)\n",
        "top_probs = torch.topk(probs, 3, dim=-1) #(T_masked, C)\n",
        "# print(idx[mask].shape)\n",
        "print(top_probs.indices)\n",
        "idx[mask] = top_probs.indices[:, 0].view(-1)\n",
        "print(top_probs.indices[:, 0].view(-1))\n",
        "idx\n",
        "# idx[mask].shape\n",
        "# pred = model.predict(x)\n",
        "# tokenizer.batch_decode(pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8EmKwwRfGNot"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYfxu7vMKAQP",
        "outputId": "e41347fd-9bd6-4556-cb1e-ff3b64f4d463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 8]), torch.Size([4, 8, 32]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape\n",
        "\n",
        "logits = torch.randn((B, T, T))\n",
        "attn = F.softmax(logits, dim=-1)\n",
        "print(attn.sum(dim=-1)) # probs sum to 1 for each token/row\n",
        "res = attn @ x\n",
        "attn.shape, res.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F76fBg8A3VBt",
        "outputId": "80b8d956-7541-4cbc-ec54-fdd5216d1b03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for self-attention, logits come from x\n",
        "logits = x @ x.transpose(-1, -2) # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
        "\n",
        "logits2 = []\n",
        "for i in range(B):\n",
        "  logits_b = []\n",
        "  for j in range(T):\n",
        "    logits_b.append(x[i, j] @ x[i].T) # (, C) @ (C, T) ---> (, T)\n",
        "\n",
        "  logits2.append(torch.stack(logits_b)) # (T, T)\n",
        "logits2 = torch.stack(logits2)\n",
        "\n",
        "torch.allclose(logits, logits2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCZUZVJe8tFN",
        "outputId": "3fafbf45-47b5-40ca-d964-4501c8675685"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 32])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "key = nn.Linear(C, C, bias=False)\n",
        "query = nn.Linear(C, C, bias=False)\n",
        "value = nn.Linear(C, C, bias=False)\n",
        "q = query(x)\n",
        "k = key(x)\n",
        "v = value(x)\n",
        "\n",
        "logits = q @ k.transpose(-1, -2) # (B, T, C) @ (B, C, T) ---> (B, T, T)\n",
        "attn = F.softmax(logits, dim=-1)\n",
        "res = attn @ v # (B, T, T) @ (B, T, C)\n",
        "res.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FyZU7PDI-XMj"
      },
      "source": [
        "Multi-head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRXRNIUyCz1y",
        "outputId": "57a088f4-0578-4e56-bdb7-2ce4f564736b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 32])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "H = 2\n",
        "C_H = C // H\n",
        "q_h = q.view(B, T, H, -1).transpose(1, 2)\n",
        "k_h = k.view(B, T, H, -1).transpose(1, 2)\n",
        "# logits = torch.randn((B, H, T, T))\n",
        "logits = q_h @ k_h.transpose(-1, -2) # (B, H, T, C_H) @ (B, H, C_H, T) ---> (B, H, T, T)\n",
        "attn = F.softmax(logits, dim=-1)\n",
        "v_h = v.view(B, T, H, -1).transpose(1, 2)\n",
        "res = attn @ v_h # (B, H, T, T) @ (B, H, T, C/H) ---> (B, H, T, C/H)\n",
        "res.shape\n",
        "res.transpose(1, 2).reshape(B, T, -1).shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6MRmb52VP8Di"
      },
      "source": [
        "Scaled: formular Var(aX), Var(X+Y) and Var(XY) in https://en.wikipedia.org/wiki/Variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP1KeDj0Q1fE",
        "outputId": "eb7b8a0f-1616-419c-b40a-eae911c0527a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
            "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
          ]
        }
      ],
      "source": [
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1))\n",
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * 8, dim=-1))\n",
        "\n",
        "# Increasing the variance of the logits makes the probs moving to more peaky,\n",
        "# coverging to one hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT2QyhCrzhMX",
        "outputId": "8698b2fe-59e2-42c3-8d76-b6c1c941a8a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.9592) tensor(0.9445) tensor(0.8309)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(93.2930)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = torch.randn(100)\n",
        "q = torch.randn(100)\n",
        "prod = k * q\n",
        "print(k.var(), q.var(), prod.var()) # var(XY) = 1\n",
        "\n",
        "k = torch.randn(T, 100)\n",
        "q = torch.randn(T, 100)\n",
        "logits = q @ k.T\n",
        "logits.var() # var(X+Y) = 2*var(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfAWAJ6JzEyk",
        "outputId": "59452585-7871-4f43-de96-6e5d4319cc14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.2408)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = torch.randn(B,T,C_H)\n",
        "q = torch.randn(B,T,C_H)\n",
        "# var(k @ q.T) = C_H * var(k)\n",
        "# var(k @ q.T * x) = C_H * var(k) * x^2\n",
        "# x^2 = 1/C_H\n",
        "wei = q @ k.transpose(-2, -1) * C_H**-0.5\n",
        "wei.var()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rc1lYtKpKB0f"
      },
      "source": [
        "### Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iPqnpb1UaaRb"
      },
      "outputs": [],
      "source": [
        "# BertModel\n",
        "#   word_embedding, pos_emdding, tk_type_emdding\n",
        "#   BertLayer *\n",
        "#     SelfAttention\n",
        "#     mlp\n",
        "#   cls_head\n",
        "#   lm_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "torch.isin(a, torch.tensor([1]))\n",
        "tokenizer.all_special_ids\n",
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vAeX18EL6pkp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.36941 M parameters\n",
            "step 0: train loss nsp=0.7088 lm=2.4274, val loss nsp=0.7062 lm=1.9838\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 189\u001b[0m\n\u001b[1;32m    185\u001b[0m         lm_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    186\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m--> 189\u001b[0m train()\n",
            "Cell \u001b[0;32mIn[13], line 179\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39miter\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: train loss nsp=\u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m lm=\u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, val loss nsp=\u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m lm=\u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39m# sample a batch of data\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m xb, yb, nsp_targets \u001b[39m=\u001b[39m get_batch(\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    181\u001b[0m \u001b[39m# evaluate the loss\u001b[39;00m\n\u001b[1;32m    182\u001b[0m _, _, nsp_loss, lm_loss \u001b[39m=\u001b[39m model(xb, lm_targets\u001b[39m=\u001b[39myb)\n",
            "Cell \u001b[0;32mIn[12], line 38\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     34\u001b[0m sents1 \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(data[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ix]\n\u001b[1;32m     35\u001b[0m \u001b[39m# sents1 = [\"\".join(data[i][: len(data[i]) // 2]) for i in ix]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# sents2 = [\"\".join(data[i][len(data[i]) // 2 :]) for i in next_ix]\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# x = tokenizer(sents1, sents2, return_tensors=\"pt\", padding=True, truncation=True)\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m x \u001b[39m=\u001b[39m tokenizer(sents1, return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     40\u001b[0m token_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(x[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     41\u001b[0m attention_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(x[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m])\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2577\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2575\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2576\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2577\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2578\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2579\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2663\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2659\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2660\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2661\u001b[0m         )\n\u001b[1;32m   2662\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2663\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2664\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2665\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2666\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2667\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2668\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2669\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2670\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2671\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2672\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2673\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2674\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2675\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2676\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2677\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2678\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2679\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2680\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2681\u001b[0m     )\n\u001b[1;32m   2682\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2683\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2684\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2685\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2701\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2702\u001b[0m     )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2854\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2846\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2847\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2852\u001b[0m )\n\u001b[0;32m-> 2854\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   2855\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2856\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2857\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2858\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2859\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2860\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2861\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2862\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2863\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2864\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2865\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2866\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2867\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2868\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2869\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2870\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2871\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2872\u001b[0m )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils.py:733\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     ids, pair_ids \u001b[39m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 733\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(ids)\n\u001b[1;32m    734\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(pair_ids) \u001b[39mif\u001b[39;00m pair_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    735\u001b[0m input_ids\u001b[39m.\u001b[39mappend((first_ids, second_ids))\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils.py:700\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_ids\u001b[39m(text):\n\u001b[1;32m    699\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 700\u001b[0m         tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(text, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    701\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    702\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils.py:547\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         tokenized_text\u001b[39m.\u001b[39mappend(token)\n\u001b[1;32m    546\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m         tokenized_text\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenize(token))\n\u001b[1;32m    548\u001b[0m \u001b[39m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39mreturn\u001b[39;00m tokenized_text\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/tokenization_bert.py:246\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_basic_tokenize:\n\u001b[1;32m    244\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbasic_tokenizer\u001b[39m.\u001b[39mtokenize(text, never_split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_special_tokens):\n\u001b[1;32m    245\u001b[0m         \u001b[39m# If the token is part of the never_split set\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m         \u001b[39mif\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasic_tokenizer\u001b[39m.\u001b[39mnever_split:\n\u001b[1;32m    247\u001b[0m             split_tokens\u001b[39m.\u001b[39mappend(token)\n\u001b[1;32m    248\u001b[0m         \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "hidden_size = 128\n",
        "num_head = 4\n",
        "drop_out = 0.0\n",
        "num_layers = 12\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
        "max_iters = 60_000\n",
        "eval_interval = 100\n",
        "lr = 1e-4\n",
        "eval_iters = 200\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "counts = Counter()\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.head_size = hidden_size // num_head\n",
        "\n",
        "        self.query = nn.Linear(hidden_size, hidden_size)\n",
        "        self.key = nn.Linear(hidden_size, hidden_size)\n",
        "        self.value = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(drop_out)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        k = k.view(B, T, num_head, -1).transpose(1, 2)  # (B, num_head, T, head_size)\n",
        "        v = self.value(x)\n",
        "        v = v.view(B, T, num_head, -1).transpose(1, 2)  # (B, num_head, T, head_size)\n",
        "        q = self.query(x)\n",
        "        q = q.view(B, T, num_head, -1).transpose(1, 2)  # (B, num_head, T, head_size)\n",
        "\n",
        "        logits = q @ k.transpose(-1, -2) / self.head_size**0.5\n",
        "        mask = mask[:, None, None, :]  # (bs, 1, 1, seq_len)\n",
        "        logits = logits.masked_fill(mask == 0, float(\"-inf\"))\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        probs = self.dropout(probs)\n",
        "        res = probs @ v  # (B, num_head, T, head_size)\n",
        "        res = res.transpose(1, 2).reshape(B, T, -1)  # (B, T, C)\n",
        "        return self.dropout(self.dense(res))  # (B, T, C)\n",
        "\n",
        "\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sa = SelfAttention()\n",
        "        self.ffwd = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 4 * hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * hidden_size, hidden_size),\n",
        "            nn.Dropout(drop_out),\n",
        "        )\n",
        "        self.ln1 = nn.LayerNorm(hidden_size)\n",
        "        self.ln2 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = x + self.sa(self.ln1(x), mask)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class BertModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.word_embedding = nn.Embedding(\n",
        "            tokenizer.vocab_size, hidden_size, padding_idx=tokenizer.pad_token_id\n",
        "        )\n",
        "        self.pos_embedding = nn.Embedding(tokenizer.model_max_length, hidden_size)\n",
        "        self.tk_type_embedding = nn.Embedding(2, hidden_size)\n",
        "        position_ids = torch.arange(tokenizer.model_max_length).unsqueeze(0)\n",
        "        self.register_buffer(\"position_ids\", position_ids)\n",
        "        self.dropout = nn.Dropout(drop_out)\n",
        "        self.ln = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self.bert_layers = nn.ModuleList([BertLayer() for _ in range(num_layers)])\n",
        "        self.ln_final = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self.cls_dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.cls_af = nn.Tanh()\n",
        "        self.cls_head = nn.Linear(hidden_size, 2)\n",
        "\n",
        "        self.lm_ln = nn.LayerNorm(hidden_size)\n",
        "        self.lm_head = nn.Linear(hidden_size, tokenizer.vocab_size, bias=False)\n",
        "        self.lm_head.weight = self.word_embedding.weight\n",
        "\n",
        "    def forward(self, encoding, nsp_targets=None, lm_targets=None):\n",
        "        ids = encoding[\"input_ids\"]  # (B, T)\n",
        "        type_ids = encoding[\"token_type_ids\"]\n",
        "        atten_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "        B, T = ids.shape\n",
        "        word_embedding = self.word_embedding(ids)\n",
        "        pos_ids = self.position_ids[:, :T]\n",
        "        pos_embedding = self.pos_embedding(pos_ids)\n",
        "        tk_type_embedding = self.tk_type_embedding(type_ids)\n",
        "        embedding = word_embedding + pos_embedding + tk_type_embedding\n",
        "        embedding = self.dropout(self.ln(embedding))\n",
        "\n",
        "        for bert_layer in self.bert_layers:\n",
        "            embedding = bert_layer(embedding, atten_mask)\n",
        "        embedding = self.ln_final(embedding)\n",
        "\n",
        "        cls_logit = self.cls_dense(embedding[:, 0])\n",
        "        cls_logit = self.cls_head(self.cls_af(cls_logit))\n",
        "        lm_logits = self.lm_head(embedding)\n",
        "\n",
        "        cls_loss = None\n",
        "        if nsp_targets is not None:\n",
        "            cls_loss = F.cross_entropy(cls_logit, nsp_targets)\n",
        "\n",
        "        lm_loss = None\n",
        "        if lm_targets is not None:\n",
        "            lm_loss = F.cross_entropy(\n",
        "                lm_logits.view(-1, lm_logits.size(-1)),\n",
        "                lm_targets.view(-1),\n",
        "                ignore_index=-100,\n",
        "            )\n",
        "\n",
        "        return cls_logit, lm_logits, cls_loss, lm_loss\n",
        "\n",
        "    def predict(self, encoding):\n",
        "        cls_logit, lm_logits, _, _ = self(encoding)  # (B, 1) (B, T, C)\n",
        "        probs = F.softmax(lm_logits, dim=-1)  # (B, T, C)\n",
        "        top_probs = torch.topk(probs, 3, dim=-1)  # (B, T, 3)\n",
        "\n",
        "        nsp = F.softmax(cls_logit, dim=-1)\n",
        "\n",
        "        #  (B, 3, T), (B, 2)\n",
        "        return top_probs.indices.transpose(1, 2), nsp\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        nsp_losses = torch.zeros(eval_iters)\n",
        "        lm_losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y, nsp_targets = get_batch(split)\n",
        "            _, _, nsp_loss, lm_loss = model(X, nsp_targets=nsp_targets, lm_targets=Y)\n",
        "            nsp_losses[k] = nsp_loss.item() if nsp_loss is not None else 0\n",
        "            lm_losses[k] = lm_loss.item() if lm_loss is not None else 0\n",
        "        out[split] = nsp_losses.mean(), lm_losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "model = BertModel()\n",
        "model = model.to(device)\n",
        "print(sum(p.numel() for p in model.parameters()) / 1e6, \"M parameters\")\n",
        "# for n, p in model.named_parameters():\n",
        "#   print(n, p.numel()/1e6, 'M')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train():\n",
        "    for iter in range(max_iters):\n",
        "        # every once in a while evaluate the loss on train and val sets\n",
        "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "            losses = estimate_loss()\n",
        "            print(\n",
        "                f\"step {iter}: train loss nsp={losses['train'][0]:.4f} lm={losses['train'][1]:.4f}, val loss nsp={losses['val'][0]:.4f} lm={losses['val'][1]:.4f}\"\n",
        "            )\n",
        "\n",
        "        # sample a batch of data\n",
        "        xb, yb, nsp_targets = get_batch(\"train\")\n",
        "\n",
        "        # evaluate the loss\n",
        "        _, _, nsp_loss, lm_loss = model(xb, lm_targets=yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # loss = nsp_loss + lm_loss\n",
        "        lm_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(\", :. the'and i to ; of a you my? that! in is not -\",\n",
              " Counter({1010: 427787,\n",
              "          1024: 233371,\n",
              "          1012: 176537,\n",
              "          1996: 131037,\n",
              "          1005: 130416,\n",
              "          1998: 124645,\n",
              "          1045: 112082,\n",
              "          2000: 102221,\n",
              "          1025: 78459,\n",
              "          1997: 74980,\n",
              "          1037: 72408,\n",
              "          2017: 71479,\n",
              "          2026: 65548,\n",
              "          1029: 55197,\n",
              "          2008: 53230,\n",
              "          999: 49892,\n",
              "          1999: 49558,\n",
              "          2003: 46694,\n",
              "          2025: 43537,\n",
              "          1011: 42898,\n",
              "          2005: 41761,\n",
              "          2022: 39265,\n",
              "          2007: 38846,\n",
              "          2033: 38815,\n",
              "          2009: 38726,\n",
              "          1055: 38329,\n",
              "          2002: 34264,\n",
              "          15223: 33608,\n",
              "          2115: 32862,\n",
              "          2021: 31861,\n",
              "          2023: 31217,\n",
              "          2031: 30556,\n",
              "          2004: 29973,\n",
              "          2010: 29270,\n",
              "          1040: 29187,\n",
              "          2054: 27695,\n",
              "          2061: 25789,\n",
              "          2015: 25572,\n",
              "          15177: 23755,\n",
              "          2032: 23536,\n",
              "          2080: 21715,\n",
              "          2097: 21701,\n",
              "          2053: 20640,\n",
              "          3695: 20629,\n",
              "          2035: 20625,\n",
              "          2102: 20220,\n",
              "          2057: 19697,\n",
              "          2014: 19645,\n",
              "          2909: 18609,\n",
              "          2011: 18074,\n",
              "          14992: 17968,\n",
              "          4618: 17768,\n",
              "          2065: 17188,\n",
              "          2024: 17184,\n",
              "          1051: 16312,\n",
              "          2079: 16202,\n",
              "          2063: 15930,\n",
              "          2085: 15716,\n",
              "          2332: 15683,\n",
              "          2256: 15227,\n",
              "          2204: 15140,\n",
              "          2272: 15070,\n",
              "          2006: 14524,\n",
              "          2232: 14138,\n",
              "          2016: 14050,\n",
              "          2030: 13950,\n",
              "          2182: 13723,\n",
              "          2175: 13713,\n",
              "          2271: 13483,\n",
              "          2012: 13001,\n",
              "          2001: 12836,\n",
              "          2129: 12559,\n",
              "          2062: 12429,\n",
              "          2029: 12359,\n",
              "          2059: 12337,\n",
              "          2222: 12105,\n",
              "          2013: 11937,\n",
              "          2935: 11904,\n",
              "          9004: 11561,\n",
              "          24665: 11555,\n",
              "          6820: 11478,\n",
              "          2027: 11388,\n",
              "          23584: 11323,\n",
              "          2052: 11319,\n",
              "          2572: 10722,\n",
              "          2092: 10638,\n",
              "          2292: 10593,\n",
              "          2360: 10284,\n",
              "          2045: 9948,\n",
              "          2100: 9914,\n",
              "          1056: 9809,\n",
              "          2084: 9613,\n",
              "          2106: 9565,\n",
              "          6045: 9389,\n",
              "          2043: 9325,\n",
              "          2073: 9294,\n",
              "          2269: 9078,\n",
              "          2068: 9071,\n",
              "          2019: 8919,\n",
              "          2293: 8898,\n",
              "          2028: 8883,\n",
              "          2191: 8673,\n",
              "          2037: 8665,\n",
              "          2089: 8590,\n",
              "          2149: 8443,\n",
              "          2135: 8437,\n",
              "          2020: 8433,\n",
              "          2339: 8261,\n",
              "          2323: 8241,\n",
              "          2066: 8201,\n",
              "          2158: 8165,\n",
              "          3804: 8153,\n",
              "          2113: 8150,\n",
              "          2588: 8094,\n",
              "          2018: 7682,\n",
              "          2664: 7640,\n",
              "          22320: 7640,\n",
              "          2050: 7298,\n",
              "          4013: 7281,\n",
              "          2442: 7137,\n",
              "          2094: 7063,\n",
              "          2034: 6943,\n",
              "          7570: 6872,\n",
              "          2273: 6847,\n",
              "          3367: 6847,\n",
              "          2040: 6835,\n",
              "          2156: 6676,\n",
              "          2202: 6652,\n",
              "          25283: 6605,\n",
              "          3067: 6596,\n",
              "          9413: 6579,\n",
              "          2070: 6576,\n",
              "          2358: 6471,\n",
              "          2107: 6366,\n",
              "          6320: 6219,\n",
              "          2205: 6182,\n",
              "          2041: 6146,\n",
              "          2425: 6133,\n",
              "          4895: 6090,\n",
              "          3713: 6027,\n",
              "          2507: 6018,\n",
              "          2365: 5996,\n",
              "          17668: 5943,\n",
              "          2039: 5938,\n",
              "          3035: 5906,\n",
              "          16778: 5885,\n",
              "          12717: 5855,\n",
              "          19913: 5850,\n",
              "          2122: 5848,\n",
              "          2957: 5750,\n",
              "          2051: 5610,\n",
              "          2643: 5530,\n",
              "          3040: 5519,\n",
              "          2532: 5518,\n",
              "          3619: 5517,\n",
              "          2038: 5501,\n",
              "          10645: 5466,\n",
              "          18428: 5440,\n",
              "          7550: 5345,\n",
              "          2963: 5249,\n",
              "          2064: 5240,\n",
              "          2087: 5219,\n",
              "          2196: 5187,\n",
              "          3487: 5140,\n",
              "          2331: 5132,\n",
              "          2098: 5089,\n",
              "          4496: 5002,\n",
              "          2154: 4996,\n",
              "          2081: 4954,\n",
              "          2121: 4922,\n",
              "          2075: 4896,\n",
              "          2396: 4876,\n",
              "          2540: 4724,\n",
              "          19731: 4716,\n",
              "          2166: 4664,\n",
              "          2228: 4621,\n",
              "          11089: 4502,\n",
              "          2185: 4456,\n",
              "          2172: 4420,\n",
              "          2888: 4416,\n",
              "          2259: 4361,\n",
              "          11839: 4355,\n",
              "          12390: 4331,\n",
              "          2298: 4323,\n",
              "          2077: 4319,\n",
              "          2078: 4253,\n",
              "          4189: 4247,\n",
              "          4086: 4247,\n",
              "          2947: 4189,\n",
              "          2567: 4146,\n",
              "          2108: 4127,\n",
              "          2119: 4123,\n",
              "          2171: 4115,\n",
              "          7174: 4077,\n",
              "          6417: 4069,\n",
              "          2655: 4060,\n",
              "          2214: 4045,\n",
              "          2589: 4027,\n",
              "          13370: 4026,\n",
              "          13629: 4025,\n",
              "          2522: 4020,\n",
              "          16012: 4017,\n",
              "          3203: 4010,\n",
              "          2151: 3929,\n",
              "          2995: 3918,\n",
              "          2153: 3897,\n",
              "          2200: 3859,\n",
              "          4372: 3800,\n",
              "          29349: 3745,\n",
              "          5292: 3723,\n",
              "          3568: 3703,\n",
              "          3685: 3698,\n",
              "          18051: 3693,\n",
              "          4135: 3682,\n",
              "          2042: 3635,\n",
              "          10414: 3618,\n",
              "          4980: 3611,\n",
              "          2219: 3588,\n",
              "          16786: 3586,\n",
              "          2295: 3581,\n",
              "          2305: 3535,\n",
              "          2870: 3514,\n",
              "          2126: 3510,\n",
              "          8945: 3509,\n",
              "          13283: 3499,\n",
              "          3310: 3485,\n",
              "          2099: 3484,\n",
              "          2564: 3475,\n",
              "          2412: 3429,\n",
              "          2684: 3404,\n",
              "          2091: 3369,\n",
              "          2192: 3367,\n",
              "          2088: 3347,\n",
              "          5736: 3324,\n",
              "          2307: 3295,\n",
              "          2146: 3292,\n",
              "          2994: 3283,\n",
              "          7015: 3279,\n",
              "          3532: 3271,\n",
              "          2818: 3236,\n",
              "          9392: 3235,\n",
              "          2681: 3207,\n",
              "          9488: 3151,\n",
              "          19662: 3129,\n",
              "          5498: 3108,\n",
              "          2498: 3095,\n",
              "          2114: 3092,\n",
              "          2140: 3083,\n",
              "          2159: 3077,\n",
              "          23238: 3068,\n",
              "          6229: 3061,\n",
              "          2488: 3051,\n",
              "          2048: 3031,\n",
              "          3571: 3001,\n",
              "          2160: 2968,\n",
              "          6516: 2939,\n",
              "          2668: 2919,\n",
              "          6225: 2897,\n",
              "          2190: 2870,\n",
              "          5802: 2858,\n",
              "          4562: 2849,\n",
              "          4857: 2842,\n",
              "          2060: 2821,\n",
              "          2989: 2775,\n",
              "          6203: 2747,\n",
              "          7794: 2746,\n",
              "          7132: 2743,\n",
              "          5743: 2740,\n",
              "          2234: 2740,\n",
              "          2773: 2736,\n",
              "          4519: 2735,\n",
              "          3233: 2731,\n",
              "          2132: 2717,\n",
              "          2125: 2716,\n",
              "          2116: 2716,\n",
              "          2453: 2714,\n",
              "          2144: 2707,\n",
              "          2842: 2696,\n",
              "          2229: 2668,\n",
              "          18595: 2667,\n",
              "          3489: 2666,\n",
              "          5886: 2624,\n",
              "          3159: 2617,\n",
              "          3288: 2606,\n",
              "          13707: 2594,\n",
              "          2791: 2576,\n",
              "          2908: 2571,\n",
              "          3696: 2567,\n",
              "          3904: 2552,\n",
              "          2812: 2545,\n",
              "          2130: 2526,\n",
              "          2518: 2519,\n",
              "          2444: 2493,\n",
              "          2117: 2487,\n",
              "          2404: 2485,\n",
              "          3005: 2481,\n",
              "          3521: 2474,\n",
              "          6014: 2470,\n",
              "          9530: 2463,\n",
              "          2571: 2456,\n",
              "          2739: 2452,\n",
              "          2210: 2430,\n",
              "          2388: 2429,\n",
              "          2320: 2426,\n",
              "          2145: 2408,\n",
              "          6160: 2397,\n",
              "          6178: 2395,\n",
              "          3280: 2390,\n",
              "          2071: 2387,\n",
              "          2188: 2381,\n",
              "          3531: 2376,\n",
              "          16126: 2376,\n",
              "          2718: 2374,\n",
              "          7226: 2361,\n",
              "          3183: 2341,\n",
              "          2216: 2336,\n",
              "          2296: 2333,\n",
              "          2814: 2332,\n",
              "          2712: 2323,\n",
              "          2096: 2322,\n",
              "          12262: 2315,\n",
              "          2717: 2307,\n",
              "          2757: 2306,\n",
              "          2777: 2305,\n",
              "          2046: 2301,\n",
              "          2562: 2296,\n",
              "          3993: 2294,\n",
              "          9195: 2293,\n",
              "          4355: 2266,\n",
              "          10170: 2263,\n",
              "          11503: 2248,\n",
              "          2424: 2247,\n",
              "          21877: 2242,\n",
              "          14933: 2229,\n",
              "          2157: 2229,\n",
              "          2705: 2227,\n",
              "          6821: 2222,\n",
              "          2227: 2190,\n",
              "          12618: 2188,\n",
              "          11805: 2181,\n",
              "          3586: 2170,\n",
              "          2275: 2169,\n",
              "          5914: 2160,\n",
              "          7987: 2156,\n",
              "          3969: 2152,\n",
              "          2907: 2114,\n",
              "          10882: 2107,\n",
              "          3011: 2105,\n",
              "          2616: 2092,\n",
              "          2067: 2092,\n",
              "          4012: 2090,\n",
              "          3658: 2087,\n",
              "          25346: 2087,\n",
              "          2370: 2080,\n",
              "          3129: 2073,\n",
              "          3523: 2072,\n",
              "          6819: 2072,\n",
              "          4570: 2059,\n",
              "          2173: 2049,\n",
              "          2056: 2046,\n",
              "          2566: 2044,\n",
              "          2440: 2042,\n",
              "          9998: 2040,\n",
              "          3426: 2039,\n",
              "          24185: 2036,\n",
              "          2044: 2025,\n",
              "          14387: 2017,\n",
              "          4416: 2017,\n",
              "          25287: 2014,\n",
              "          5262: 2006,\n",
              "          6506: 1999,\n",
              "          3401: 1992,\n",
              "          2543: 1989,\n",
              "          4173: 1985,\n",
              "          17836: 1978,\n",
              "          2265: 1977,\n",
              "          7913: 1972,\n",
              "          2449: 1967,\n",
              "          10323: 1955,\n",
              "          28210: 1942,\n",
              "          2657: 1937,\n",
              "          2785: 1929,\n",
              "          3246: 1928,\n",
              "          8040: 1927,\n",
              "          2568: 1923,\n",
              "          2373: 1922,\n",
              "          5506: 1917,\n",
              "          2361: 1915,\n",
              "          2055: 1907,\n",
              "          2306: 1905,\n",
              "          4509: 1892,\n",
              "          2386: 1888,\n",
              "          7947: 1881,\n",
              "          8140: 1878,\n",
              "          2393: 1875,\n",
              "          4410: 1865,\n",
              "          12776: 1857,\n",
              "          4067: 1840,\n",
              "          5545: 1825,\n",
              "          3103: 1811,\n",
              "          7216: 1810,\n",
              "          2112: 1806,\n",
              "          7871: 1805,\n",
              "          2521: 1803,\n",
              "          2387: 1800,\n",
              "          12700: 1799,\n",
              "          13407: 1797,\n",
              "          2093: 1795,\n",
              "          6569: 1786,\n",
              "          9467: 1784,\n",
              "          14038: 1784,\n",
              "          9307: 1769,\n",
              "          13433: 1769,\n",
              "          19084: 1769,\n",
              "          12487: 1766,\n",
              "          9289: 1754,\n",
              "          2111: 1754,\n",
              "          3201: 1748,\n",
              "          4180: 1748,\n",
              "          2398: 1744,\n",
              "          3507: 1724,\n",
              "          21442: 1712,\n",
              "          2450: 1709,\n",
              "          3437: 1698,\n",
              "          2302: 1690,\n",
              "          2377: 1689,\n",
              "          2058: 1683,\n",
              "          8737: 1682,\n",
              "          2203: 1675,\n",
              "          21146: 1673,\n",
              "          4682: 1668,\n",
              "          3239: 1663,\n",
              "          7096: 1662,\n",
              "          2879: 1653,\n",
              "          4133: 1653,\n",
              "          3113: 1649,\n",
              "          5939: 1646,\n",
              "          2738: 1644,\n",
              "          2389: 1641,\n",
              "          10486: 1640,\n",
              "          2047: 1637,\n",
              "          2402: 1634,\n",
              "          2128: 1627,\n",
              "          21658: 1627,\n",
              "          2224: 1625,\n",
              "          4017: 1622,\n",
              "          26927: 1617,\n",
              "          4487: 1611,\n",
              "          19763: 1608,\n",
              "          3870: 1599,\n",
              "          2178: 1599,\n",
              "          3560: 1593,\n",
              "          6011: 1592,\n",
              "          6300: 1591,\n",
              "          3610: 1587,\n",
              "          2793: 1584,\n",
              "          3913: 1583,\n",
              "          4921: 1579,\n",
              "          2187: 1576,\n",
              "          3308: 1571,\n",
              "          19863: 1567,\n",
              "          8108: 1561,\n",
              "          2197: 1555,\n",
              "          21862: 1555,\n",
              "          2515: 1554,\n",
              "          8959: 1550,\n",
              "          4752: 1546,\n",
              "          11693: 1543,\n",
              "          2903: 1539,\n",
              "          6926: 1535,\n",
              "          3240: 1527,\n",
              "          2110: 1526,\n",
              "          2239: 1525,\n",
              "          3422: 1525,\n",
              "          2614: 1521,\n",
              "          3084: 1518,\n",
              "          2775: 1518,\n",
              "          3637: 1517,\n",
              "          8415: 1512,\n",
              "          2422: 1505,\n",
              "          20228: 1504,\n",
              "          2162: 1504,\n",
              "          2890: 1498,\n",
              "          3329: 1491,\n",
              "          2477: 1491,\n",
              "          3582: 1484,\n",
              "          2131: 1478,\n",
              "          2928: 1470,\n",
              "          4611: 1469,\n",
              "          22701: 1461,\n",
              "          7280: 1457,\n",
              "          10760: 1450,\n",
              "          3126: 1449,\n",
              "          12296: 1445,\n",
              "          3267: 1444,\n",
              "          4595: 1444,\n",
              "          4000: 1443,\n",
              "          2462: 1441,\n",
              "          7221: 1433,\n",
              "          9191: 1425,\n",
              "          2831: 1424,\n",
              "          4199: 1424,\n",
              "          3342: 1423,\n",
              "          2965: 1422,\n",
              "          3504: 1421,\n",
              "          4025: 1416,\n",
              "          5542: 1414,\n",
              "          23998: 1409,\n",
              "          2546: 1408,\n",
              "          2860: 1403,\n",
              "          6270: 1403,\n",
              "          2069: 1403,\n",
              "          9940: 1396,\n",
              "          4382: 1394,\n",
              "          4326: 1390,\n",
              "          4604: 1383,\n",
              "          3828: 1381,\n",
              "          2245: 1381,\n",
              "          3178: 1376,\n",
              "          2104: 1376,\n",
              "          3549: 1369,\n",
              "          11031: 1358,\n",
              "          2746: 1341,\n",
              "          18523: 1330,\n",
              "          2905: 1329,\n",
              "          2368: 1329,\n",
              "          2767: 1327,\n",
              "          3543: 1325,\n",
              "          6767: 1323,\n",
              "          9686: 1323,\n",
              "          17328: 1322,\n",
              "          3268: 1321,\n",
              "          16215: 1317,\n",
              "          10250: 1317,\n",
              "          3147: 1315,\n",
              "          6542: 1315,\n",
              "          2342: 1311,\n",
              "          2086: 1310,\n",
              "          2083: 1308,\n",
              "          3606: 1308,\n",
              "          7966: 1306,\n",
              "          13675: 1301,\n",
              "          6925: 1299,\n",
              "          12063: 1299,\n",
              "          3043: 1295,\n",
              "          11113: 1293,\n",
              "          2819: 1293,\n",
              "          2991: 1293,\n",
              "          2735: 1290,\n",
              "          1041: 1288,\n",
              "          12690: 1287,\n",
              "          4426: 1287,\n",
              "          13894: 1281,\n",
              "          9587: 1281,\n",
              "          22889: 1273,\n",
              "          24941: 1272,\n",
              "          7098: 1270,\n",
              "          2438: 1269,\n",
              "          2556: 1265,\n",
              "          3334: 1263,\n",
              "          2303: 1262,\n",
              "          2703: 1261,\n",
              "          10943: 1259,\n",
              "          2496: 1258,\n",
              "          12831: 1258,\n",
              "          3094: 1254,\n",
              "          2439: 1254,\n",
              "          3372: 1251,\n",
              "          3510: 1248,\n",
              "          3102: 1247,\n",
              "          9691: 1247,\n",
              "          2625: 1245,\n",
              "          20113: 1240,\n",
              "          15603: 1235,\n",
              "          5223: 1227,\n",
              "          21200: 1227,\n",
              "          2716: 1222,\n",
              "          3841: 1220,\n",
              "          16360: 1220,\n",
              "          2729: 1218,\n",
              "          10424: 1215,\n",
              "          2300: 1212,\n",
              "          2353: 1211,\n",
              "          18410: 1208,\n",
              "          2548: 1200,\n",
              "          14161: 1199,\n",
              "          3981: 1198,\n",
              "          21547: 1194,\n",
              "          2308: 1193,\n",
              "          13777: 1190,\n",
              "          2608: 1187,\n",
              "          11246: 1180,\n",
              "          4797: 1179,\n",
              "          3174: 1179,\n",
              "          12722: 1179,\n",
              "          3413: 1178,\n",
              "          3726: 1178,\n",
              "          3407: 1175,\n",
              "          5339: 1172,\n",
              "          10850: 1172,\n",
              "          5897: 1170,\n",
              "          2409: 1170,\n",
              "          17311: 1169,\n",
              "          2194: 1168,\n",
              "          4840: 1167,\n",
              "          28173: 1165,\n",
              "          2375: 1163,\n",
              "          2758: 1163,\n",
              "          4788: 1160,\n",
              "          1038: 1155,\n",
              "          3404: 1153,\n",
              "          6242: 1150,\n",
              "          5932: 1148,\n",
              "          2406: 1148,\n",
              "          19569: 1146,\n",
              "          11218: 1144,\n",
              "          17727: 1142,\n",
              "          13109: 1140,\n",
              "          6548: 1140,\n",
              "          2457: 1137,\n",
              "          4231: 1136,\n",
              "          6737: 1135,\n",
              "          11017: 1132,\n",
              "          27874: 1131,\n",
              "          16205: 1130,\n",
              "          4299: 1130,\n",
              "          11007: 1130,\n",
              "          12731: 1128,\n",
              "          3238: 1127,\n",
              "          2290: 1127,\n",
              "          2455: 1117,\n",
              "          14955: 1117,\n",
              "          15333: 1115,\n",
              "          4687: 1113,\n",
              "          7481: 1112,\n",
              "          7874: 1111,\n",
              "          3653: 1110,\n",
              "          5665: 1110,\n",
              "          10264: 1108,\n",
              "          8024: 1103,\n",
              "          26241: 1103,\n",
              "          18484: 1101,\n",
              "          15138: 1101,\n",
              "          5391: 1097,\n",
              "          2103: 1091,\n",
              "          2464: 1090,\n",
              "          2545: 1085,\n",
              "          18584: 1084,\n",
              "          12798: 1084,\n",
              "          7646: 1084,\n",
              "          2362: 1081,\n",
              "          4470: 1079,\n",
              "          4540: 1077,\n",
              "          5053: 1075,\n",
              "          2180: 1072,\n",
              "          13422: 1072,\n",
              "          11739: 1070,\n",
              "          11292: 1069,\n",
              "          3435: 1068,\n",
              "          3786: 1066,\n",
              "          11265: 1065,\n",
              "          2574: 1064,\n",
              "          14021: 1059,\n",
              "          2250: 1059,\n",
              "          3715: 1058,\n",
              "          8673: 1057,\n",
              "          7861: 1056,\n",
              "          19181: 1055,\n",
              "          3529: 1051,\n",
              "          2469: 1051,\n",
              "          28553: 1050,\n",
              "          3800: 1048,\n",
              "          9684: 1048,\n",
              "          4014: 1044,\n",
              "          2383: 1044,\n",
              "          3442: 1043,\n",
              "          6703: 1038,\n",
              "          4283: 1036,\n",
              "          5551: 1034,\n",
              "          2138: 1031,\n",
              "          8285: 1027,\n",
              "          3114: 1025,\n",
              "          14573: 1021,\n",
              "          3191: 1019,\n",
              "          3827: 1018,\n",
              "          18856: 1017,\n",
              "          3866: 1014,\n",
              "          2326: 1013,\n",
              "          11703: 1013,\n",
              "          2147: 1012,\n",
              "          28616: 1010,\n",
              "          11133: 1010,\n",
              "          2213: 1007,\n",
              "          18766: 1006,\n",
              "          2854: 1005,\n",
              "          3082: 1004,\n",
              "          2711: 1001,\n",
              "          3388: 1001,\n",
              "          2741: 1000,\n",
              "          15854: 1000,\n",
              "          2141: 998,\n",
              "          3013: 997,\n",
              "          3279: 997,\n",
              "          6865: 993,\n",
              "          4690: 992,\n",
              "          11074: 989,\n",
              "          21358: 988,\n",
              "          4151: 988,\n",
              "          3338: 983,\n",
              "          6658: 983,\n",
              "          9995: 982,\n",
              "          15912: 981,\n",
              "          2378: 979,\n",
              "          5390: 978,\n",
              "          2593: 974,\n",
              "          4282: 970,\n",
              "          26760: 970,\n",
              "          2287: 969,\n",
              "          8739: 966,\n",
              "          2489: 965,\n",
              "          8072: 962,\n",
              "          2152: 958,\n",
              "          7195: 955,\n",
              "          3959: 955,\n",
              "          24748: 953,\n",
              "          2336: 953,\n",
              "          10404: 950,\n",
              "          2379: 950,\n",
              "          4929: 943,\n",
              "          2310: 941,\n",
              "          10606: 941,\n",
              "          5705: 940,\n",
              "          2627: 939,\n",
              "          2169: 937,\n",
              "          9831: 936,\n",
              "          6240: 934,\n",
              "          3002: 933,\n",
              "          23277: 932,\n",
              "          4301: 931,\n",
              "          4183: 928,\n",
              "          2894: 928,\n",
              "          2420: 928,\n",
              "          2954: 926,\n",
              "          1059: 924,\n",
              "          8840: 923,\n",
              "          11752: 918,\n",
              "          9148: 917,\n",
              "          4894: 917,\n",
              "          2448: 914,\n",
              "          10883: 913,\n",
              "          5017: 909,\n",
              "          7425: 908,\n",
              "          23166: 906,\n",
              "          2748: 903,\n",
              "          7782: 895,\n",
              "          4776: 894,\n",
              "          5011: 894,\n",
              "          4462: 893,\n",
              "          6289: 892,\n",
              "          2436: 891,\n",
              "          4875: 891,\n",
              "          2124: 889,\n",
              "          6346: 887,\n",
              "          6181: 886,\n",
              "          3730: 883,\n",
              "          2848: 880,\n",
              "          5285: 878,\n",
              "          3052: 878,\n",
              "          8740: 875,\n",
              "          4257: 875,\n",
              "          17223: 875,\n",
              "          8215: 875,\n",
              "          2431: 872,\n",
              "          2277: 872,\n",
              "          2919: 870,\n",
              "          11981: 868,\n",
              "          2397: 868,\n",
              "          2691: 868,\n",
              "          7968: 865,\n",
              "          3189: 864,\n",
              "          2354: 864,\n",
              "          2709: 861,\n",
              "          8254: 860,\n",
              "          4175: 860,\n",
              "          9619: 858,\n",
              "          2784: 858,\n",
              "          6200: 855,\n",
              "          9517: 854,\n",
              "          2830: 850,\n",
              "          2411: 845,\n",
              "          7918: 845,\n",
              "          2598: 845,\n",
              "          4937: 844,\n",
              "          9841: 844,\n",
              "          17649: 843,\n",
              "          2417: 842,\n",
              "          11870: 842,\n",
              "          8300: 840,\n",
              "          15966: 839,\n",
              "          7178: 836,\n",
              "          5463: 834,\n",
              "          2847: 834,\n",
              "          2330: 833,\n",
              "          22277: 832,\n",
              "          18413: 831,\n",
              "          2479: 830,\n",
              "          2242: 829,\n",
              "          5293: 829,\n",
              "          27541: 828,\n",
              "          8295: 826,\n",
              "          4832: 826,\n",
              "          27534: 824,\n",
              "          5643: 824,\n",
              "          2563: 820,\n",
              "          4328: 819,\n",
              "          2961: 818,\n",
              "          7971: 814,\n",
              "          2198: 812,\n",
              "          2335: 811,\n",
              "          3425: 810,\n",
              "          2391: 808,\n",
              "          3762: 807,\n",
              "          4654: 807,\n",
              "          3468: 807,\n",
              "          2665: 806,\n",
              "          3710: 806,\n",
              "          19817: 805,\n",
              "          4095: 805,\n",
              "          3000: 804,\n",
              "          3538: 803,\n",
              "          2435: 802,\n",
              "          10553: 802,\n",
              "          2849: 800,\n",
              "          3632: 798,\n",
              "          3917: 798,\n",
              "          16375: 797,\n",
              "          12096: 797,\n",
              "          8616: 796,\n",
              "          26693: 794,\n",
              "          4356: 794,\n",
              "          18533: 793,\n",
              "          7416: 792,\n",
              "          10930: 791,\n",
              "          4099: 790,\n",
              "          11937: 790,\n",
              "          4088: 789,\n",
              "          11721: 789,\n",
              "          2702: 786,\n",
              "          2215: 782,\n",
              "          12638: 779,\n",
              "          6517: 779,\n",
              "          10696: 777,\n",
              "          2344: 774,\n",
              "          4103: 772,\n",
              "          10722: 769,\n",
              "          2090: 767,\n",
              "          5004: 766,\n",
              "          15470: 765,\n",
              "          4848: 763,\n",
              "          6954: 763,\n",
              "          2274: 760,\n",
              "          16056: 760,\n",
              "          17766: 759,\n",
              "          7735: 758,\n",
              "          4009: 757,\n",
              "          8670: 756,\n",
              "          2553: 756,\n",
              "          2980: 756,\n",
              "          2471: 753,\n",
              "          4521: 753,\n",
              "          2165: 751,\n",
              "          9772: 751,\n",
              "          4138: 749,\n",
              "          3109: 745,\n",
              "          5165: 741,\n",
              "          5485: 738,\n",
              "          4558: 737,\n",
              "          7459: 737,\n",
              "          3111: 736,\n",
              "          2074: 735,\n",
              "          3198: 734,\n",
              "          2492: 731,\n",
              "          2082: 730,\n",
              "          12242: 729,\n",
              "          3395: 728,\n",
              "          24763: 726,\n",
              "          21902: 725,\n",
              "          5927: 724,\n",
              "          2663: 722,\n",
              "          9293: 722,\n",
              "          4445: 720,\n",
              "          2607: 718,\n",
              "          6770: 718,\n",
              "          19725: 716,\n",
              "          2247: 715,\n",
              "          2911: 714,\n",
              "          2524: 714,\n",
              "          3170: 713,\n",
              "          4685: 710,\n",
              "          25472: 710,\n",
              "          6313: 705,\n",
              "          8189: 702,\n",
              "          25154: 701,\n",
              "          3749: 699,\n",
              "          2666: 698,\n",
              "          2279: 697,\n",
              "          10050: 697,\n",
              "          16130: 697,\n",
              "          4906: 695,\n",
              "          6148: 693,\n",
              "          3634: 692,\n",
              "          4792: 692,\n",
              "          13102: 692,\n",
              "          4553: 691,\n",
              "          3385: 690,\n",
              "          5122: 689,\n",
              "          19668: 688,\n",
              "          6655: 687,\n",
              "          4480: 686,\n",
              "          3600: 685,\n",
              "          13219: 685,\n",
              "          6713: 684,\n",
              "          4530: 684,\n",
              "          10190: 684,\n",
              "          3768: 684,\n",
              "          11897: 684,\n",
              "          10750: 684,\n",
              "          2179: 684,\n",
              "          2969: 683,\n",
              "          2689: 683,\n",
              "          4641: 680,\n",
              "          2236: 679,\n",
              "          10975: 679,\n",
              "          2514: 677,\n",
              "          2986: 677,\n",
              "          3085: 676,\n",
              "          2852: 676,\n",
              "          2560: 672,\n",
              "          14644: 669,\n",
              "          3612: 668,\n",
              "          2693: 667,\n",
              "          2844: 665,\n",
              "          2445: 665,\n",
              "          4574: 665,\n",
              "          3064: 664,\n",
              "          2970: 664,\n",
              "          3366: 663,\n",
              "          6340: 663,\n",
              "          5819: 661,\n",
              "          2605: 658,\n",
              "          2869: 658,\n",
              "          9015: 658,\n",
              "          2674: 657,\n",
              "          8116: 656,\n",
              "          10497: 655,\n",
              "          2217: 654,\n",
              "          3168: 654,\n",
              "          15046: 653,\n",
              "          12583: 653,\n",
              "          5205: 652,\n",
              "          6716: 652,\n",
              "          16021: 651,\n",
              "          29278: 645,\n",
              "          17114: 644,\n",
              "          21025: 644,\n",
              "          5227: 643,\n",
              "          9471: 643,\n",
              "          5596: 642,\n",
              "          2595: 642,\n",
              "          6812: 642,\n",
              "          2338: 641,\n",
              "          2606: 640,\n",
              "          6499: 638,\n",
              "          9152: 638,\n",
              "          2682: 637,\n",
              "          7324: 634,\n",
              "          2468: 633,\n",
              "          4766: 632,\n",
              "          17211: 629,\n",
              "          3574: 629,\n",
              "          12825: 628,\n",
              "          4854: 625,\n",
              "          6843: 624,\n",
              "          2993: 624,\n",
              "          7386: 623,\n",
              "          2516: 622,\n",
              "          12006: 620,\n",
              "          2168: 618,\n",
              "          21055: 618,\n",
              "          16368: 617,\n",
              "          15264: 617,\n",
              "          13961: 616,\n",
              "          11867: 616,\n",
              "          2341: 615,\n",
              "          4756: 613,\n",
              "          25426: 612,\n",
              "          4748: 611,\n",
              "          2618: 610,\n",
              "          26260: 610,\n",
              "          3849: 609,\n",
              "          ...}))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode([token for token, count in counts.most_common(20)]), counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "Qws1z_gkNgnU",
        "outputId": "ad376218-e8e7-4824-89f7-17248313f205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 83]) torch.Size([16, 83]) torch.Size([16, 3, 83])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>input</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>first</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>##sp</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>##tor</td>\n",
              "      <td>:</td>\n",
              "      <td>so</td>\n",
              "      <td>he</td>\n",
              "      <td>did</td>\n",
              "      <td>,</td>\n",
              "      <td>my</td>\n",
              "      <td>lord</td>\n",
              "      <td>:</td>\n",
              "      <td>the</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>marvel</td>\n",
              "      <td>##l</td>\n",
              "      <td>'</td>\n",
              "      <td>d</td>\n",
              "      <td>at</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "      <td>,</td>\n",
              "      <td>in</td>\n",
              "      <td>##ʑ</td>\n",
              "      <td>last</td>\n",
              "      <td>,</td>\n",
              "      <td>when</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>had</td>\n",
              "      <td>carried</td>\n",
              "      <td>rome</td>\n",
              "      <td>and</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>we</td>\n",
              "      <td>look</td>\n",
              "      <td>'</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>for</td>\n",
              "      <td>no</td>\n",
              "      <td>less</td>\n",
              "      <td>spoil</td>\n",
              "      <td>than</td>\n",
              "      <td>glory</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>##idi</td>\n",
              "      <td>##us</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>there</td>\n",
              "      <td>was</td>\n",
              "      <td>it</td>\n",
              "      <td>:</td>\n",
              "      <td>for</td>\n",
              "      <td>which</td>\n",
              "      <td>my</td>\n",
              "      <td>sin</td>\n",
              "      <td>##ew</td>\n",
              "      <td>##s</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>be</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>'</td>\n",
              "      <td>d</td>\n",
              "      <td>[MASK]</td>\n",
              "      <td>him</td>\n",
              "      <td>.</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[PAD]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>con</td>\n",
              "      <td></td>\n",
              "      <td>##ira</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>army</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>it</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>the</td>\n",
              "      <td>last</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>he</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>that</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>d</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>auf</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>:</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>shall</td>\n",
              "      <td></td>\n",
              "      <td>stretch</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>upon</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred1</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>con</td>\n",
              "      <td></td>\n",
              "      <td>##ira</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td>last</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred2</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>king</td>\n",
              "      <td></td>\n",
              "      <td>,</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>:</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>the</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>s</td>\n",
              "      <td>moved</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>he</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>and</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>he</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>and</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>:</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>to</td>\n",
              "      <td></td>\n",
              "      <td>to</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>and</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred3</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>if</td>\n",
              "      <td></td>\n",
              "      <td>##man</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>##s</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>had</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>i</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>:</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>:</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>a</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>and</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>and</td>\n",
              "      <td></td>\n",
              "      <td>the</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>the</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0      1       2     3       4      5  6   7   8    9  10  11  \\\n",
              "input   [CLS]  first  [MASK]  ##sp  [MASK]  ##tor  :  so  he  did  ,  my   \n",
              "target                   con         ##ira                                 \n",
              "pred1                    con         ##ira                                 \n",
              "pred2                   king             ,                                 \n",
              "pred3                     if         ##man                                 \n",
              "\n",
              "          12 13   14      15      16   17 18 19  20      21 22   23 24  25  \\\n",
              "input   lord  :  the  [MASK]  marvel  ##l  '  d  at  [MASK]  ,  and  ,  in   \n",
              "target                  army                             it                  \n",
              "pred1                      ,                              ,                  \n",
              "pred2                      :                            the                  \n",
              "pred3                      ;                            ##s                  \n",
              "\n",
              "         26     27 28    29      30   31       32    33   34      35  36  \\\n",
              "input   ##ʑ   last  ,  when  [MASK]  had  carried  rome  and  [MASK]  we   \n",
              "target  the   last               he                             that       \n",
              "pred1     ,   last                ,                                ,       \n",
              "pred2     s  moved               he                              and       \n",
              "pred3     ;    had                i                                :       \n",
              "\n",
              "          37 38      39   40  41    42     43    44     45      46 47 48  \\\n",
              "input   look  '  [MASK]  for  no  less  spoil  than  glory  [MASK]  -  -   \n",
              "target                d                                          ,         \n",
              "pred1                 ,                                          ,         \n",
              "pred2                 ;                                         he         \n",
              "pred3                 :                                          -         \n",
              "\n",
              "            49     50    51      52     53   54  55 56   57     58  59   60  \\\n",
              "input   [MASK]  ##idi  ##us  [MASK]  there  was  it  :  for  which  my  sin   \n",
              "target     auf                    :                                           \n",
              "pred1        ,                    ,                                           \n",
              "pred2      and                    :                                           \n",
              "pred3        a                  and                                           \n",
              "\n",
              "          61   62      63  64       65 66 67      68   69 70     71     72  \\\n",
              "input   ##ew  ##s  [MASK]  be   [MASK]  '  d  [MASK]  him  .  [SEP]  [PAD]   \n",
              "target              shall      stretch          upon                         \n",
              "pred1                   ,            ,             ,                         \n",
              "pred2                  to           to           and                         \n",
              "pred3                 and          the           the                         \n",
              "\n",
              "           73     74     75     76     77     78     79     80     81     82  \n",
              "input   [PAD]  [PAD]  [PAD]  [PAD]  [PAD]  [PAD]  [PAD]  [PAD]  [PAD]  [PAD]  \n",
              "target                                                                        \n",
              "pred1                                                                         \n",
              "pred2                                                                         \n",
              "pred3                                                                         "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "xb, yb, nsp_targets = get_batch('train')\n",
        "input = [[tokenizer.decode([id]) for id in x] for x in xb['input_ids']]\n",
        "target = [[tokenizer.decode([id]) if id != -100 else \"\" for id in y] for y in yb]\n",
        "# model(xb, lm_targets=yb)\n",
        "pred, nsp = model.predict(xb)\n",
        "\n",
        "print(xb['input_ids'].shape, yb.shape, pred.shape)\n",
        "# print(xb['input_ids'][0])\n",
        "# print(yb[0])\n",
        "# print(xb['token_type_ids'][0])\n",
        "# print(xb['attention_mask'][0])\n",
        "\n",
        "pred_list = [[[tokenizer.decode([id]) if yid != -100 else \"\" for id, yid in zip(p, y)] for p in p3] for p3, y in zip(pred, yb)]\n",
        "# len(input), len(target), len(pred_list)\n",
        "df = pd.DataFrame({'input': input[0], 'target': target[0],\n",
        "                   'pred1': pred_list[0][0], # (B, rank)\n",
        "                   'pred2': pred_list[0][1],\n",
        "                   'pred3': pred_list[0][2]})\n",
        "df.T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "pv0gtpN4ZS7G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
              "        [-100, -100, -100,  ..., -100, -100, -100],\n",
              "        [-100, -100, -100,  ..., -100, -100, -100],\n",
              "        ...,\n",
              "        [-100, -100, -100,  ..., -100, -100, -100],\n",
              "        [-100, -100, 2698,  ..., -100, -100, -100],\n",
              "        [-100, -100, -100,  ..., -100, -100, -100]])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xb, yb, nsp = get_batch('train')\n",
        "yb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNj3Mh9qocpJXm8VX98pxvd",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00df2531c1964177912eda85ff390b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3698ed92044b15bf6a1add32c59151",
            "placeholder": "​",
            "style": "IPY_MODEL_7d92183a905345d7893b16afd52bff98",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "0150e70c287e41a7aa63f4b311a4fb20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03e8910cec704b9faf3785419a074d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61bb426559ab4a26a03616f919d3f5e7",
            "placeholder": "​",
            "style": "IPY_MODEL_cea3af583b07467d8d0d780be52bffb0",
            "value": " 570/570 [00:00&lt;00:00, 7.58kB/s]"
          }
        },
        "0a75ebb318994fef87c5245d76386b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16fa3a6d20d44b748755c6559988ee29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bf9a5c56b9c45f3988298bfe23ffbeb",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52c8091c5a91410884c4cc4eb63ab664",
            "value": 570
          }
        },
        "194b763975f94027933438a9f61db312": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fdc3f2bc066456181a119e2626253f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a70a4070369943d786c5f6419bc7855e",
              "IPY_MODEL_16fa3a6d20d44b748755c6559988ee29",
              "IPY_MODEL_03e8910cec704b9faf3785419a074d51"
            ],
            "layout": "IPY_MODEL_194b763975f94027933438a9f61db312"
          }
        },
        "27d788ede01d4a63ba5623947dfcc610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d1e130563a4d8d9899a2c172ac0b7e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a75ebb318994fef87c5245d76386b7c",
            "value": " 28.0/28.0 [00:00&lt;00:00, 299B/s]"
          }
        },
        "44823a0f1dc745b797344c864dcaf9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c8091c5a91410884c4cc4eb63ab664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ba53621b5404299b4bccd0ecc793b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738470260044459c88f2fcab1601601c",
            "placeholder": "​",
            "style": "IPY_MODEL_e1c54fb227ff4c4dbdd71e71beffc60e",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "61bb426559ab4a26a03616f919d3f5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bf9a5c56b9c45f3988298bfe23ffbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c47f2dd4a8b42d5aac221e1f1d9e49a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738470260044459c88f2fcab1601601c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d92183a905345d7893b16afd52bff98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d8b6965c49b4de8a00d6353ca5ce3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44823a0f1dc745b797344c864dcaf9ab",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cff6d96ada8f4abc95f2c9309abd9fdd",
            "value": 231508
          }
        },
        "90d1e130563a4d8d9899a2c172ac0b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3698ed92044b15bf6a1add32c59151": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a70a4070369943d786c5f6419bc7855e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce6194ae648140c7b78029418bdfa9ef",
            "placeholder": "​",
            "style": "IPY_MODEL_c39d642238cc49d8b9de1586b3e2cd53",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ba4df94adffa4420818c508ef5f7845a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00df2531c1964177912eda85ff390b44",
              "IPY_MODEL_e76b393bc34f4b55a738acc581c363ae",
              "IPY_MODEL_27d788ede01d4a63ba5623947dfcc610"
            ],
            "layout": "IPY_MODEL_eb4d44035640476b8814a7bbd191bd8a"
          }
        },
        "bb31d174d5b9436084d67a8d02ee7cba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c39d642238cc49d8b9de1586b3e2cd53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce6194ae648140c7b78029418bdfa9ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea3af583b07467d8d0d780be52bffb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cff6d96ada8f4abc95f2c9309abd9fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d482d6cd9cc542e0b96c5223f24ac632": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c54fb227ff4c4dbdd71e71beffc60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e76b393bc34f4b55a738acc581c363ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d482d6cd9cc542e0b96c5223f24ac632",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f101c3efd4f044349897ac02ef3ecf2b",
            "value": 28
          }
        },
        "e7c3b0369c7e48849f3328bf066975cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ba53621b5404299b4bccd0ecc793b4f",
              "IPY_MODEL_8d8b6965c49b4de8a00d6353ca5ce3d0",
              "IPY_MODEL_fc323784e2f7494d93425704d21a0643"
            ],
            "layout": "IPY_MODEL_6c47f2dd4a8b42d5aac221e1f1d9e49a"
          }
        },
        "eb4d44035640476b8814a7bbd191bd8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f101c3efd4f044349897ac02ef3ecf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc323784e2f7494d93425704d21a0643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb31d174d5b9436084d67a8d02ee7cba",
            "placeholder": "​",
            "style": "IPY_MODEL_0150e70c287e41a7aa63f4b311a4fb20",
            "value": " 232k/232k [00:00&lt;00:00, 3.93MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
